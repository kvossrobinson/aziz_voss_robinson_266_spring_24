{"cells":[{"cell_type":"markdown","source":["# README\n","\n","**Purpose**\n","\n","Fine tune the pre-trained HuggingFace RoBERTa base on domain-specific NER with the dataset of your choice\n","\n","**How-To**\n","\n","Make any updates in the \"Update Each Run\" section before running all cells. Places to take particular care:\n","\n","\n","*   output_model - If you forget to change this and have overwrite set to True, you will erase whatever was previously in the folder.\n","*   overwrite - This must be set to False if you are training from a checkpoint.\n","*   name - I'm not sure this is getting used, but I've been updating it anyway.\n","\n"],"metadata":{"id":"RBt0eAlgBMu2"}},{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"bPnMEvC_9HEz"}},{"cell_type":"markdown","source":["## Will Need Regular Changes"],"metadata":{"id":"66H42RDz9Hfa"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"UK37MFQN2rxO"},"outputs":[],"source":["## Training Args\n","\n","# Where to put the model outputs\n","output_path = '/content/drive/MyDrive/266/source_of_truth/baseline_models/domain_specific_ner'\n","\n","# Are you training?\n","do_train_flag = True\n","\n","# Are you evaluating?\n","do_eval_flag = True\n","\n","# Number of train epochs\n","epoch_count = 2\n","\n","# Number of save steps\n","save_step_count = 1000\n","\n","# Number of eval steps\n","eval_step_count = 1000 # Keep same as logging_steps\n","\n","# Number of logging steps\n","logging_step_count = eval_step_count # Keep same as logging_steps\n","\n","# Overwrite Output Dir - MUST be False if you're training from a checkpoint\n","overwrite = True\n","\n","# Run Name\n","name = 'Domain-specific NER on MIT movie corpus - 2 epochs'"]},{"cell_type":"markdown","source":["## Will *Not* Need Regular Changes"],"metadata":{"id":"7TIABThw9H_x"}},{"cell_type":"code","source":["## Data Args\n","\n","# Path to get the domain-specific NER data\n","data_path = '/content/drive/My Drive/266/source_of_truth/data/'\n","\n","## Preprocessing within Main\n","train_tag_scheme = ['B-ACTOR',\n","                    'B-CHARACTER',\n","                    'B-DIRECTOR',\n","                    'B-GENRE',\n","                    'B-PLOT',\n","                    'B-RATING',\n","                    'B-RATINGS_AVERAGE',\n","                    'B-REVIEW',\n","                    'B-SONG',\n","                    'B-TITLE',\n","                    'B-TRAILER',\n","                    'B-YEAR',\n","                    'I-ACTOR',\n","                    'I-CHARACTER',\n","                    'I-DIRECTOR',\n","                    'I-GENRE',\n","                    'I-PLOT',\n","                    'I-RATING',\n","                    'I-RATINGS_AVERAGE',\n","                    'I-REVIEW',\n","                    'I-SONG',\n","                    'I-TITLE',\n","                    'I-TRAILER',\n","                    'I-YEAR',\n","                    'O']"],"metadata":{"id":"WNAamZD1_-pA"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21961,"status":"ok","timestamp":1712450712710,"user":{"displayName":"Katherine Voss-Robinson","userId":"10124239414397994450"},"user_tz":300},"id":"jnfsWsXvRKXA","outputId":"fe5a8437-7e0d-4821-fca0-962518ff24a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i9dp9sY4Tgtf","executionInfo":{"status":"ok","timestamp":1712450834111,"user_tz":300,"elapsed":121405,"user":{"displayName":"Katherine Voss-Robinson","userId":"10124239414397994450"}},"outputId":"572a427e-2f8a-4d3c-bd48-2f9ab3511dc0"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.3/297.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install -q evaluate\n","!pip install -q datasets\n","!pip install -q accelerate -U\n","!pip install -q seqeval"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0taF9kX5RTXM"},"outputs":[],"source":["import logging\n","import os\n","import sys\n","import warnings\n","from dataclasses import dataclass, field\n","from typing import Optional, Tuple, Union, List, Dict\n","\n","import datasets\n","import evaluate\n","import numpy as np\n","from datasets import ClassLabel, load_dataset\n","\n","import transformers\n","from transformers import (\n","    AutoConfig,\n","    AutoModelForTokenClassification,\n","    AutoTokenizer,\n","    DataCollatorForTokenClassification,\n","    HfArgumentParser,\n","    PretrainedConfig,\n","    PreTrainedTokenizerFast,\n","    Trainer,\n","    TrainingArguments,\n","    set_seed,\n","    RobertaPreTrainedModel, RobertaModel, RobertaConfig\n",")\n","from transformers.trainer_utils import get_last_checkpoint\n","from transformers.utils import check_min_version, send_example_telemetry, ModelOutput\n","from transformers.utils.versions import require_version\n","\n","import torch\n","import torch.utils.checkpoint\n","from torch import nn\n","from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss"]},{"cell_type":"markdown","source":["# Custom Model"],"metadata":{"id":"AV2YxQVKEh6r"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5DeDuN5DT2yU"},"outputs":[],"source":["@dataclass\n","class TokenClassifierOutput(ModelOutput):\n","    \"\"\"\n","    Base class for outputs of token classification models.\n","\n","    Args:\n","        loss (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels` is provided) :\n","            Classification loss.\n","        logits (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.num_labels)`):\n","            Classification scores (before SoftMax).\n","        hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`):\n","            Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model has an embedding layer, +\n","            one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.\n","\n","            Hidden-states of the model at the output of each layer plus the optional initial embedding outputs.\n","        attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`):\n","            Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length,\n","            sequence_length)`.\n","\n","            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n","            heads.\n","    \"\"\"\n","\n","    loss: Optional[torch.FloatTensor] = None\n","    logits: torch.FloatTensor = None\n","    hidden_states: Optional[Tuple[torch.FloatTensor, ...]] = None\n","    attentions: Optional[Tuple[torch.FloatTensor, ...]] = None\n","\n","class RobertaForTokenClassification(RobertaPreTrainedModel):\n","    def __init__(self, config):\n","        super().__init__(config)\n","        self.num_labels = config.num_labels\n","\n","        self.roberta = RobertaModel(config, add_pooling_layer=False)\n","        classifier_dropout = (\n","            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n","        )\n","        self.dropout = nn.Dropout(classifier_dropout)\n","        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n","\n","        # Initialize weights and apply final processing\n","        self.post_init()\n","\n","    def forward(\n","        self,\n","        input_ids: Optional[torch.LongTensor] = None,\n","        attention_mask: Optional[torch.FloatTensor] = None,\n","        token_type_ids: Optional[torch.LongTensor] = None,\n","        position_ids: Optional[torch.LongTensor] = None,\n","        head_mask: Optional[torch.FloatTensor] = None,\n","        inputs_embeds: Optional[torch.FloatTensor] = None,\n","        labels: Optional[torch.LongTensor] = None,\n","        output_attentions: Optional[bool] = None,\n","        output_hidden_states: Optional[bool] = None,\n","        return_dict: Optional[bool] = None,\n","    ) -> Union[Tuple[torch.Tensor], TokenClassifierOutput]:\n","        r\"\"\"\n","        labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n","            Labels for computing the token classification loss. Indices should be in `[0, ..., config.num_labels - 1]`.\n","        \"\"\"\n","        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","\n","        outputs = self.roberta(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=token_type_ids,\n","            position_ids=position_ids,\n","            head_mask=head_mask,\n","            inputs_embeds=inputs_embeds,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,\n","        )\n","\n","        sequence_output = outputs[0]\n","\n","        sequence_output = self.dropout(sequence_output)\n","        logits = self.classifier(sequence_output)\n","\n","        loss = None\n","        if labels is not None:\n","            # move labels to correct device to enable model parallelism\n","            labels = labels.to(logits.device)\n","            loss_fct = CrossEntropyLoss()\n","            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n","\n","        if not return_dict:\n","          output = (logits,) + outputs[2:]\n","          return ((loss,) + output) if loss is not None else output\n","\n","        return TokenClassifierOutput(\n","            loss=loss,\n","            logits=logits,\n","            hidden_states=outputs.hidden_states,\n","            attentions=outputs.attentions,\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-QVmnfY_T-0s"},"outputs":[],"source":["# Setting logger\n","logger = logging.getLogger(__name__)\n","TRAINED_MODEL = None"]},{"cell_type":"markdown","metadata":{"id":"TYxaK6knRUGj"},"source":["# Classes"]},{"cell_type":"markdown","source":["## MetricsLogger"],"metadata":{"id":"OI5VOF0e9cvu"}},{"cell_type":"code","source":["from transformers import TrainerCallback\n","\n","class MetricsLogger(TrainerCallback):\n","    \"A logger that will store metrics after each evaluation.\"\n","    def __init__(self):\n","        self.metrics = []\n","\n","    def on_log(self, args, state, control, logs=None, **kwargs):\n","        if logs is not None:\n","            # You can add more metrics here if needed\n","            self.metrics.append({\n","                \"step\": state.global_step,\n","                \"loss\": logs.get(\"loss\", None),\n","                \"eval_loss\": logs.get(\"eval_loss\", None),\n","            })\n","\n","# Initialize your logger\n","metrics_logger = MetricsLogger()\n"],"metadata":{"id":"XHoSARQ8ttLz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## ModelArguments"],"metadata":{"id":"RfWh61M99e19"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"0wx7lqvRRUOP"},"outputs":[],"source":["@dataclass\n","class ModelArguments:\n","    \"\"\"\n","    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n","    \"\"\"\n","\n","    model_name_or_path: str = field(\n","        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n","    )\n","    config_name: Optional[str] = field(\n","        default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n","    )\n","    tokenizer_name: Optional[str] = field(\n","        default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n","    )\n","    cache_dir: Optional[str] = field(\n","        default=None,\n","        metadata={\"help\": \"Where do you want to store the pretrained models downloaded from huggingface.co\"},\n","    )\n","    model_revision: str = field(\n","        default=\"main\",\n","        metadata={\"help\": \"The specific model version to use (can be a branch name, tag name or commit id).\"},\n","    )\n","    token: str = field(\n","        default=None,\n","        metadata={\n","            \"help\": (\n","                \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n","                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n","            )\n","        },\n","    )\n","    use_auth_token: bool = field(\n","        default=None,\n","        metadata={\n","            \"help\": \"The `use_auth_token` argument is deprecated and will be removed in v4.34. Please use `token` instead.\"\n","        },\n","    )\n","    trust_remote_code: bool = field(\n","        default=False,\n","        metadata={\n","            \"help\": (\n","                \"Whether or not to allow for custom models defined on the Hub in their own modeling files. This option \"\n","                \"should only be set to `True` for repositories you trust and in which you have read the code, as it will \"\n","                \"execute code present on the Hub on your local machine.\"\n","            )\n","        },\n","    )\n","    ignore_mismatched_sizes: bool = field(\n","        default=False,\n","        metadata={\"help\": \"Will enable to load a pretrained model whose head dimensions are different.\"},\n","    )"]},{"cell_type":"markdown","source":["## DataTrainingArguments"],"metadata":{"id":"cVig-fx89ghX"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"GXPu2alXUI0Y"},"outputs":[],"source":["@dataclass\n","class DataTrainingArguments:\n","    \"\"\"\n","    Arguments pertaining to what data we are going to input our model for training and eval.\n","    \"\"\"\n","\n","    task_name: Optional[str] = field(default=\"ner\", metadata={\"help\": \"The name of the task (ner, pos...).\"})\n","    dataset_name: Optional[str] = field(\n","        default=None, metadata={\"help\": \"The name of the dataset to use (via the datasets library).\"}\n","    )\n","    dataset_config_name: Optional[str] = field(\n","        default=None, metadata={\"help\": \"The configuration name of the dataset to use (via the datasets library).\"}\n","    )\n","    train_file: Optional[str] = field(\n","        default=None, metadata={\"help\": \"The input training data file (a csv or JSON file).\"}\n","    )\n","    validation_file: Optional[str] = field(\n","        default=None,\n","        metadata={\"help\": \"An optional input evaluation data file to evaluate on (a csv or JSON file).\"},\n","    )\n","    test_file: Optional[str] = field(\n","        default=None,\n","        metadata={\"help\": \"An optional input test data file to predict on (a csv or JSON file).\"},\n","    )\n","    text_column_name: Optional[str] = field(\n","        default=None, metadata={\"help\": \"The column name of text to input in the file (a csv or JSON file).\"}\n","    )\n","    label_column_name: Optional[str] = field(\n","        default=None, metadata={\"help\": \"The column name of label to input in the file (a csv or JSON file).\"}\n","    )\n","    overwrite_cache: bool = field(\n","        default=False, metadata={\"help\": \"Overwrite the cached training and evaluation sets\"}\n","    )\n","    preprocessing_num_workers: Optional[int] = field(\n","        default=None,\n","        metadata={\"help\": \"The number of processes to use for the preprocessing.\"},\n","    )\n","    max_seq_length: int = field(\n","        default=None,\n","        metadata={\n","            \"help\": (\n","                \"The maximum total input sequence length after tokenization. If set, sequences longer \"\n","                \"than this will be truncated, sequences shorter will be padded.\"\n","            )\n","        },\n","    )\n","    pad_to_max_length: bool = field(\n","        default=False,\n","        metadata={\n","            \"help\": (\n","                \"Whether to pad all samples to model maximum sentence length. \"\n","                \"If False, will pad the samples dynamically when batching to the maximum length in the batch. More \"\n","                \"efficient on GPU but very bad for TPU.\"\n","            )\n","        },\n","    )\n","    max_train_samples: Optional[int] = field(\n","        default=None,\n","        metadata={\n","            \"help\": (\n","                \"For debugging purposes or quicker training, truncate the number of training examples to this \"\n","                \"value if set.\"\n","            )\n","        },\n","    )\n","    max_eval_samples: Optional[int] = field(\n","        default=None,\n","        metadata={\n","            \"help\": (\n","                \"For debugging purposes or quicker training, truncate the number of evaluation examples to this \"\n","                \"value if set.\"\n","            )\n","        },\n","    )\n","    max_predict_samples: Optional[int] = field(\n","        default=None,\n","        metadata={\n","            \"help\": (\n","                \"For debugging purposes or quicker training, truncate the number of prediction examples to this \"\n","                \"value if set.\"\n","            )\n","        },\n","    )\n","    label_all_tokens: bool = field(\n","        default=False,\n","        metadata={\n","            \"help\": (\n","                \"Whether to put the label for one word on all tokens of generated by that word or just on the \"\n","                \"one (in which case the other tokens will have a padding index).\"\n","            )\n","        },\n","    )\n","    return_entity_level_metrics: bool = field(\n","        default=False,\n","        metadata={\"help\": \"Whether to return all the entity levels during evaluation or just the overall ones.\"},\n","    )\n","\n","    def __post_init__(self):\n","        if self.dataset_name is None and self.train_file is None and self.validation_file is None:\n","            raise ValueError(\"Need either a dataset name or a training/validation file.\")\n","        else:\n","            if self.train_file is not None:\n","                extension = self.train_file.split(\".\")[-1]\n","                assert extension in [\"csv\", \"json\"], \"`train_file` should be a csv or a json file.\"\n","            if self.validation_file is not None:\n","                extension = self.validation_file.split(\".\")[-1]\n","                assert extension in [\"csv\", \"json\"], \"`validation_file` should be a csv or a json file.\"\n","        self.task_name = self.task_name.lower()"]},{"cell_type":"markdown","metadata":{"id":"UPrbWKuIRU65"},"source":["# Main"]},{"cell_type":"markdown","metadata":{"id":"ba67RcGQRVIC"},"source":["## Creating Args"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4EowQUcAVOzJ"},"outputs":[],"source":["# Creating instances of the three required classes\n","\n","model_args = ModelArguments(model_name_or_path = \"roberta-base\")\n","\n","data_args = DataTrainingArguments(train_file = data_path + 'plain_training.json',\n","                                  validation_file = data_path + 'plain_val.json',\n","                                  test_file = data_path + 'plain_test.json',\n","                                  max_seq_length = 384,\n","                                  overwrite_cache = True\n","                                  )\n","\n","training_args = TrainingArguments(output_dir = output_path,\n","                                  do_train = do_train_flag,\n","                                  do_eval = do_eval_flag,\n","                                  num_train_epochs = epoch_count,\n","                                  save_strategy = \"epoch\",\n","                                  evaluation_strategy = \"epoch\",\n","                                  save_total_limit = 2,\n","                                  per_device_train_batch_size = 16,\n","                                  per_device_eval_batch_size = 10,\n","                                  overwrite_output_dir = overwrite,\n","                                  run_name = name\n","                                  )"]},{"cell_type":"markdown","metadata":{"id":"qUtQfOn4RVWC"},"source":["## Training the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SzzG5hM-RVc4","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["082457e0884646cd905c3014534acefe","dfbe687cde0e4e398f8e1d0e6e6ca8f5","124e35e1a46640c38c06f22ab1181071","1899ad40bc654c948dfcd2899ca24b04","fcd826d5ab5847f598424213c2ad3cbc","8e9524d2889a4f2bbc20f72a6b47993c","378cf71c1ac948139462a77b0a6c37ee","20bfbe0b37404e748dd026cf325fac38","3a648572d6384bddac21784045e5b9a4","95007e02739849ae8323f97d1a5f92a8","869aebdec95e4b6ba1d0cf1decd43420","40771489dd2e4cb383e8a12bf3962191","2807e03ef07e45a585a516e0d548d62e","6d38a48a05bf4b01949d4c11ca4b69e9","e2b2b1a79dbe422390a71be4ce1adfa9","65be8bd9a43044059d64f607519043f0","2b68c762942f4686899c965c23b78759","445dd9b3776e4fbba35a282cc1d478c5","651d230a3f284ed6822002729f389c10","690c107f7e7341f0b3be275b9afedbc7","3339bc2782bc4a13addb94c7bf1c28ea","51906c345a8b46d499f27165f18925ba","ce0999a4af894029b57d65cb34194d14","2ba0f2434e7c4410a48d788ec1e54dc7","02ccdbda8e2046b2b7f8d0b05c354958","0b52b9614339478a814e09b084aaa78c","911f631f1c0f4d0ba5446f1d2a5afcc5","d0dbbcd0d74d46ebbc30b488f3bdf454","99ce10237312484aaf4ee47e98407188","862f4dff545d4c57bd739ef2ee4e1d79","1047a4c5e18d445ab15759d78c25b10b","a4d76fea3031429998c02ce8559315de","c1d55306e12e471aaaf44d994cc6a5da","66cec72637c540afafe33f115206e962","582830cff56c45a393c65ce5a6b77fb2","3878dbe229ad407794a9d3b96e1859cc","7e0b25ac74d945cf9e33603dc6660a95","4a99ec99c7eb46f6b0a001394673a944","a4896d292316486e97d6a9622d23968c","0102ccded263475ba4190ff61675f179","ace490aa4b644c7480f46fd988a56592","dcf4c01119c2416bbddf532032b2c4e0","dd97c17a8aae47b68216fb5c2cda726e","f2c36897bc8d46069993619a4677d5af","1016481749384e56aa44b860b64e1087","e0960b9000584fe0906874b3ac34a9bf","9e9b75201303442381bc052afcbed30f","dccc43aa74044afc81553a0d50522e17","960f06cc99ad4f92b655bd8d8fc3809a","e60bfedf8b60495890712fff01a90843","5b4ed21512ed4e9a8418aa6cd9fda017","c60e4b20156d404cac5cde724c5f45e5","d37099d2dea24db4acc3ea3645c14d27","b707363cbf4d4624b835c5781f2382f5","f40341b8a14a4d6ca15a02a96c80c93c","68120606909444729e7d140c1b4e64d3","d5008726888042d6a55a9b58fa4e22d9","81cee552cc9645dfb3299592c94b8b07","7d71c00ba42c41e789e3c21fdb13afb6","821147a0590c44dfa8e91d18a6cb3a36","a4d9e21a86464aacad34b3eee281d884","bc620cbb420d4a19b099224d7cdc1bd0","4bc0037a9be9424d8324938adb9db32e","6a42e42aea144f0888d4f6b68e9712fd","5d6795cfa1bd4f2fb06a96047539c4dc","780f54a584194eab8de7ed959fa13138","14298011c9354338b1ae7d643d73de31","163324e96bea4d2dbe61c0b239b9d0cc","f8d5c56dbd3a4b998aa8bca5353a1ca2","0a8ac9f5b7004a5bbcdad5da17eee7d4","b624dc3952b540ab81588c5c447183e9","68c35d7a8c2847909be08761478d0afc","1e9a3b7cc3d643b3a91e74d92798295b","934cf611e13e4af38d12d1c114687dae","fc83fcf57cd74143a23f29d50de3dc69","0e8749bd686449f4a00dea803d716ee7","4e13093b938d42e6874f45eee06bdacd","06b860467fda4a39b2176e5477ef2bdb","d8f098a9411b446280c3e5cfadb8447c","235b49a27c614e1c91820762e7bf809f","c0c13caf751e45b29e8c2a0e8ec6cec1","cbc8285dd43a412098b0eab24d445454","318fd4943741427f972e4707a12ac7bb","0f7cce8d7a144e46ba60a010cb2ce179","4985cab45c244e378833e1b6bf8ef770","54d43fbbb90d48ea87f1486f9be8aac0","8eec0e1abdff4474aa08eb594ca02e46","e759f65a04eb44eeb86753a650042b06","31a11a618312458d8d03c1609f3aa776","2353b733a38a4fefa6934f65c52a9b84","702fa9e502564b5eb343c975fbd802d6","0130d29a317c41d6905aedb91a134153","17f474fca3bc471e97cf1d6c72c2bdef","32f7d5e75fc1464dbcec68d3e3a2ec51","980565427bf143048f62e536919599ae","e37e2620c6f94a418dc8183f1f3a3302","009b9816f7884498a86b80e1e03b1a12","b232aa7f45474028bd25c0ad649b68e8","362fbfc9814c48cba88419167fe7546c","aabf116a3fa24708b8f5ac08609d66a5","5311913692fa4841a718cb71312c9442","0481097551e14e20b37d0ed1ea9f8618","0ca3542ce6134396bb9bdf1c37537ba1","46408c166b7941da9cdd8249d0d8dd65","ec8d68d483de4c7a9b6b2ba7c75b00da","4ac2c87c208044c19009728ee9ae3244","45f9d3901e304b3693257eb9a818b91c","0bfd420ce5f94fe5b42747bdd6c4621e","264ef242d25f4cf4afb6739bb4133612","095429075ba34721823e7e470a25ca2e","1a1c7f856b554ced847db56833362a60","bb488b3ebbc446dba28d835841c71e2f","491b7fcc91c043c1b86991b6fb04b061","f37bd178d0de472589b1c91edc5d4a9c","f7809024647d4bf3a591f27bd96eea32","7ea48551b835452bb9994164414bab0c","126b178349ae4fd39255a964ef5e6bc9","d8d6255f54d54e2eb349391b8428d207","f0fc81af3ffc46ec9c4238b61d6a13ba","67ee6ef1f9b9440e8736e2750c7c00c4","b0114c37a4864bad897aa5bfbf1993a4","51e7f26907794de2b5935416b9f7deb3","47c688c96fee47a4aa8eddb2c6b67f8f","8ed46f4368fb4291853077f25d829cae","b447c176e5eb451391dab57418cd000d","867aa84be3cd4027b271f5d75143be3b","d6edd1f360314504bfe60cb8d31b3a5b","2d26e159560e4606bd846952114b999a","ca8711bc74ff4aafa08225ff0836fb6b","a2d29c5166bc48e8b0b3bae17fc2914d","612225d3982342718398633e008921bc","8d140318a3b848df94fb20b795529456"]},"executionInfo":{"status":"ok","timestamp":1712451150824,"user_tz":300,"elapsed":298225,"user":{"displayName":"Katherine Voss-Robinson","userId":"10124239414397994450"}},"outputId":"100e97cd-1c20-4eb5-9b35-9c7a6235cca9"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:__main__:Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n","INFO:__main__:Training/evaluation parameters TrainingArguments(\n","_n_gpu=1,\n","accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_persistent_workers=False,\n","dataloader_pin_memory=True,\n","dataloader_prefetch_factor=None,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=False,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_steps=None,\n","evaluation_strategy=epoch,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","gradient_checkpointing_kwargs=None,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=False,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_inputs_for_metrics=False,\n","include_num_input_tokens_seen=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=/content/drive/MyDrive/266/source_of_truth/baseline_models/domain_specific_ner/runs/Apr07_00-47-32_0aea7d6714e3,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_kwargs={},\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","neftune_noise_alpha=None,\n","no_cuda=False,\n","num_train_epochs=2,\n","optim=adamw_torch,\n","optim_args=None,\n","output_dir=/content/drive/MyDrive/266/source_of_truth/baseline_models/domain_specific_ner,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=10,\n","per_device_train_batch_size=16,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard'],\n","resume_from_checkpoint=None,\n","run_name=Domain-specific NER on MIT movie corpus - 2 epochs,\n","save_on_each_node=False,\n","save_only_model=False,\n","save_safetensors=True,\n","save_steps=500,\n","save_strategy=epoch,\n","save_total_limit=2,\n","seed=42,\n","skip_memory_metrics=True,\n","split_batches=None,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torchdynamo=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","Using custom data configuration default-68b35fe6e3e85351\n","INFO:datasets.builder:Using custom data configuration default-68b35fe6e3e85351\n","Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","INFO:datasets.info:Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","Generating dataset json (/root/.cache/huggingface/datasets/json/default-68b35fe6e3e85351/0.0.0/ab573428e7a11a7e23eebd41a2a71665ac3789ce311cbad7049572034a9bda05)\n","INFO:datasets.builder:Generating dataset json (/root/.cache/huggingface/datasets/json/default-68b35fe6e3e85351/0.0.0/ab573428e7a11a7e23eebd41a2a71665ac3789ce311cbad7049572034a9bda05)\n","Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-68b35fe6e3e85351/0.0.0/ab573428e7a11a7e23eebd41a2a71665ac3789ce311cbad7049572034a9bda05...\n","INFO:datasets.builder:Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-68b35fe6e3e85351/0.0.0/ab573428e7a11a7e23eebd41a2a71665ac3789ce311cbad7049572034a9bda05...\n","Downloading took 0.0 min\n","INFO:datasets.download.download_manager:Downloading took 0.0 min\n","Checksum Computation took 0.0 min\n","INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n","Generating train split\n","INFO:datasets.builder:Generating train split\n"]},{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"082457e0884646cd905c3014534acefe"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Generating validation split\n","INFO:datasets.builder:Generating validation split\n"]},{"output_type":"display_data","data":{"text/plain":["Generating validation split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40771489dd2e4cb383e8a12bf3962191"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Generating test split\n","INFO:datasets.builder:Generating test split\n"]},{"output_type":"display_data","data":{"text/plain":["Generating test split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce0999a4af894029b57d65cb34194d14"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Unable to verify splits sizes.\n","INFO:datasets.utils.info_utils:Unable to verify splits sizes.\n","Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-68b35fe6e3e85351/0.0.0/ab573428e7a11a7e23eebd41a2a71665ac3789ce311cbad7049572034a9bda05. Subsequent calls will reuse this data.\n","INFO:datasets.builder:Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-68b35fe6e3e85351/0.0.0/ab573428e7a11a7e23eebd41a2a71665ac3789ce311cbad7049572034a9bda05. Subsequent calls will reuse this data.\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66cec72637c540afafe33f115206e962"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[INFO|configuration_utils.py:728] 2024-04-07 00:47:39,778 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--roberta-base/snapshots/e2da8e2f811d1448a5b465c236feacd80ffbac7b/config.json\n","[INFO|configuration_utils.py:791] 2024-04-07 00:47:39,789 >> Model config RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"finetuning_task\": \"ner\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\",\n","    \"6\": \"LABEL_6\",\n","    \"7\": \"LABEL_7\",\n","    \"8\": \"LABEL_8\",\n","    \"9\": \"LABEL_9\",\n","    \"10\": \"LABEL_10\",\n","    \"11\": \"LABEL_11\",\n","    \"12\": \"LABEL_12\",\n","    \"13\": \"LABEL_13\",\n","    \"14\": \"LABEL_14\",\n","    \"15\": \"LABEL_15\",\n","    \"16\": \"LABEL_16\",\n","    \"17\": \"LABEL_17\",\n","    \"18\": \"LABEL_18\",\n","    \"19\": \"LABEL_19\",\n","    \"20\": \"LABEL_20\",\n","    \"21\": \"LABEL_21\",\n","    \"22\": \"LABEL_22\",\n","    \"23\": \"LABEL_23\",\n","    \"24\": \"LABEL_24\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_10\": 10,\n","    \"LABEL_11\": 11,\n","    \"LABEL_12\": 12,\n","    \"LABEL_13\": 13,\n","    \"LABEL_14\": 14,\n","    \"LABEL_15\": 15,\n","    \"LABEL_16\": 16,\n","    \"LABEL_17\": 17,\n","    \"LABEL_18\": 18,\n","    \"LABEL_19\": 19,\n","    \"LABEL_2\": 2,\n","    \"LABEL_20\": 20,\n","    \"LABEL_21\": 21,\n","    \"LABEL_22\": 22,\n","    \"LABEL_23\": 23,\n","    \"LABEL_24\": 24,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5,\n","    \"LABEL_6\": 6,\n","    \"LABEL_7\": 7,\n","    \"LABEL_8\": 8,\n","    \"LABEL_9\": 9\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.38.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1016481749384e56aa44b860b64e1087"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[INFO|configuration_utils.py:728] 2024-04-07 00:47:40,045 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--roberta-base/snapshots/e2da8e2f811d1448a5b465c236feacd80ffbac7b/config.json\n","[INFO|configuration_utils.py:791] 2024-04-07 00:47:40,054 >> Model config RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.38.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n"]},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68120606909444729e7d140c1b4e64d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14298011c9354338b1ae7d643d73de31"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06b860467fda4a39b2176e5477ef2bdb"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[INFO|tokenization_utils_base.py:2046] 2024-04-07 00:47:41,542 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--roberta-base/snapshots/e2da8e2f811d1448a5b465c236feacd80ffbac7b/vocab.json\n","[INFO|tokenization_utils_base.py:2046] 2024-04-07 00:47:41,544 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--roberta-base/snapshots/e2da8e2f811d1448a5b465c236feacd80ffbac7b/merges.txt\n","[INFO|tokenization_utils_base.py:2046] 2024-04-07 00:47:41,545 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--roberta-base/snapshots/e2da8e2f811d1448a5b465c236feacd80ffbac7b/tokenizer.json\n","[INFO|tokenization_utils_base.py:2046] 2024-04-07 00:47:41,546 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:2046] 2024-04-07 00:47:41,548 >> loading file special_tokens_map.json from cache at None\n","[INFO|tokenization_utils_base.py:2046] 2024-04-07 00:47:41,549 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--roberta-base/snapshots/e2da8e2f811d1448a5b465c236feacd80ffbac7b/tokenizer_config.json\n","[INFO|configuration_utils.py:728] 2024-04-07 00:47:41,552 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--roberta-base/snapshots/e2da8e2f811d1448a5b465c236feacd80ffbac7b/config.json\n","[INFO|configuration_utils.py:791] 2024-04-07 00:47:41,554 >> Model config RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.38.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31a11a618312458d8d03c1609f3aa776"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[INFO|modeling_utils.py:3257] 2024-04-07 00:47:46,885 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--roberta-base/snapshots/e2da8e2f811d1448a5b465c236feacd80ffbac7b/model.safetensors\n","[INFO|modeling_utils.py:3982] 2024-04-07 00:47:48,015 >> Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForTokenClassification: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[WARNING|modeling_utils.py:3994] 2024-04-07 00:47:48,022 >> Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["Running tokenizer on train dataset:   0%|          | 0/7820 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aabf116a3fa24708b8f5ac08609d66a5"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Caching processed dataset at /root/.cache/huggingface/datasets/json/default-68b35fe6e3e85351/0.0.0/ab573428e7a11a7e23eebd41a2a71665ac3789ce311cbad7049572034a9bda05/cache-ed1248a04b60daab.arrow\n","INFO:datasets.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/json/default-68b35fe6e3e85351/0.0.0/ab573428e7a11a7e23eebd41a2a71665ac3789ce311cbad7049572034a9bda05/cache-ed1248a04b60daab.arrow\n"]},{"output_type":"display_data","data":{"text/plain":["Running tokenizer on validation dataset:   0%|          | 0/1955 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a1c7f856b554ced847db56833362a60"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Caching processed dataset at /root/.cache/huggingface/datasets/json/default-68b35fe6e3e85351/0.0.0/ab573428e7a11a7e23eebd41a2a71665ac3789ce311cbad7049572034a9bda05/cache-783c160c7b1f96ba.arrow\n","INFO:datasets.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/json/default-68b35fe6e3e85351/0.0.0/ab573428e7a11a7e23eebd41a2a71665ac3789ce311cbad7049572034a9bda05/cache-783c160c7b1f96ba.arrow\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/6.34k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51e7f26907794de2b5935416b9f7deb3"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n","[INFO|trainer.py:759] 2024-04-07 00:47:52,920 >> The following columns in the training set don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `RobertaForTokenClassification.forward`,  you can safely ignore this message.\n","[INFO|trainer.py:1812] 2024-04-07 00:47:52,960 >> ***** Running training *****\n","[INFO|trainer.py:1813] 2024-04-07 00:47:52,962 >>   Num examples = 7,820\n","[INFO|trainer.py:1814] 2024-04-07 00:47:52,964 >>   Num Epochs = 2\n","[INFO|trainer.py:1815] 2024-04-07 00:47:52,966 >>   Instantaneous batch size per device = 16\n","[INFO|trainer.py:1818] 2024-04-07 00:47:52,968 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n","[INFO|trainer.py:1819] 2024-04-07 00:47:52,969 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:1820] 2024-04-07 00:47:52,970 >>   Total optimization steps = 978\n","[INFO|trainer.py:1821] 2024-04-07 00:47:52,973 >>   Number of trainable parameters = 124,074,265\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='978' max='978' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [978/978 03:29, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.241168</td>\n","      <td>0.860166</td>\n","      <td>0.871186</td>\n","      <td>0.865641</td>\n","      <td>0.939858</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.393600</td>\n","      <td>0.204590</td>\n","      <td>0.878245</td>\n","      <td>0.890519</td>\n","      <td>0.884340</td>\n","      <td>0.947694</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[INFO|trainer.py:759] 2024-04-07 00:48:35,223 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `RobertaForTokenClassification.forward`,  you can safely ignore this message.\n","[INFO|trainer.py:3376] 2024-04-07 00:48:35,231 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3378] 2024-04-07 00:48:35,231 >>   Num examples = 1955\n","[INFO|trainer.py:3381] 2024-04-07 00:48:35,234 >>   Batch size = 10\n","[INFO|trainer.py:3067] 2024-04-07 00:49:32,874 >> Saving model checkpoint to /content/drive/MyDrive/266/source_of_truth/baseline_models/domain_specific_ner/tmp-checkpoint-489\n","[INFO|configuration_utils.py:473] 2024-04-07 00:49:32,885 >> Configuration saved in /content/drive/MyDrive/266/source_of_truth/baseline_models/domain_specific_ner/tmp-checkpoint-489/config.json\n","[INFO|modeling_utils.py:2454] 2024-04-07 00:49:35,596 >> Model weights saved in /content/drive/MyDrive/266/source_of_truth/baseline_models/domain_specific_ner/tmp-checkpoint-489/model.safetensors\n","[INFO|tokenization_utils_base.py:2459] 2024-04-07 00:49:35,609 >> tokenizer config file saved in /content/drive/MyDrive/266/source_of_truth/baseline_models/domain_specific_ner/tmp-checkpoint-489/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2468] 2024-04-07 00:49:36,267 >> Special tokens file saved in /content/drive/MyDrive/266/source_of_truth/baseline_models/domain_specific_ner/tmp-checkpoint-489/special_tokens_map.json\n","[INFO|trainer.py:759] 2024-04-07 00:50:14,678 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `RobertaForTokenClassification.forward`,  you can safely ignore this message.\n","[INFO|trainer.py:3376] 2024-04-07 00:50:14,682 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3378] 2024-04-07 00:50:14,684 >>   Num examples = 1955\n","[INFO|trainer.py:3381] 2024-04-07 00:50:14,686 >>   Batch size = 10\n","[INFO|trainer.py:3067] 2024-04-07 00:51:13,458 >> Saving model checkpoint to /content/drive/MyDrive/266/source_of_truth/baseline_models/domain_specific_ner/tmp-checkpoint-978\n","[INFO|configuration_utils.py:473] 2024-04-07 00:51:13,467 >> Configuration saved in /content/drive/MyDrive/266/source_of_truth/baseline_models/domain_specific_ner/tmp-checkpoint-978/config.json\n","[INFO|modeling_utils.py:2454] 2024-04-07 00:51:15,565 >> Model weights saved in /content/drive/MyDrive/266/source_of_truth/baseline_models/domain_specific_ner/tmp-checkpoint-978/model.safetensors\n","[INFO|tokenization_utils_base.py:2459] 2024-04-07 00:51:15,577 >> tokenizer config file saved in /content/drive/MyDrive/266/source_of_truth/baseline_models/domain_specific_ner/tmp-checkpoint-978/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2468] 2024-04-07 00:51:15,586 >> Special tokens file saved in /content/drive/MyDrive/266/source_of_truth/baseline_models/domain_specific_ner/tmp-checkpoint-978/special_tokens_map.json\n","[INFO|trainer.py:2067] 2024-04-07 00:51:24,501 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","[INFO|trainer.py:3067] 2024-04-07 00:51:24,512 >> Saving model checkpoint to /content/drive/MyDrive/266/source_of_truth/baseline_models/domain_specific_ner\n","[INFO|configuration_utils.py:473] 2024-04-07 00:51:24,522 >> Configuration saved in /content/drive/MyDrive/266/source_of_truth/baseline_models/domain_specific_ner/config.json\n","[INFO|modeling_utils.py:2454] 2024-04-07 00:51:27,055 >> Model weights saved in /content/drive/MyDrive/266/source_of_truth/baseline_models/domain_specific_ner/model.safetensors\n","[INFO|tokenization_utils_base.py:2459] 2024-04-07 00:51:27,068 >> tokenizer config file saved in /content/drive/MyDrive/266/source_of_truth/baseline_models/domain_specific_ner/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2468] 2024-04-07 00:51:27,079 >> Special tokens file saved in /content/drive/MyDrive/266/source_of_truth/baseline_models/domain_specific_ner/special_tokens_map.json\n","INFO:__main__:*** Evaluate ***\n","[INFO|trainer.py:759] 2024-04-07 00:51:27,690 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `RobertaForTokenClassification.forward`,  you can safely ignore this message.\n","[INFO|trainer.py:3376] 2024-04-07 00:51:27,696 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3378] 2024-04-07 00:51:27,702 >>   Num examples = 1955\n","[INFO|trainer.py:3381] 2024-04-07 00:51:27,703 >>   Batch size = 10\n"]},{"output_type":"stream","name":"stdout","text":["***** train metrics *****\n","  epoch                    =        2.0\n","  total_flos               =   177694GF\n","  train_loss               =     0.2961\n","  train_runtime            = 0:03:31.52\n","  train_samples            =       7820\n","  train_samples_per_second =     73.938\n","  train_steps_per_second   =      4.623\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='196' max='196' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [196/196 01:01]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["***** eval metrics *****\n","  epoch                   =        2.0\n","  eval_accuracy           =     0.9477\n","  eval_f1                 =     0.8843\n","  eval_loss               =     0.2046\n","  eval_precision          =     0.8782\n","  eval_recall             =     0.8905\n","  eval_runtime            = 0:01:02.48\n","  eval_samples            =       1955\n","  eval_samples_per_second =     31.286\n","  eval_steps_per_second   =      3.137\n"]},{"output_type":"stream","name":"stderr","text":["[INFO|modelcard.py:450] 2024-04-07 00:52:30,621 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Token Classification', 'type': 'token-classification'}, 'metrics': [{'name': 'Precision', 'type': 'precision', 'value': 0.8782448885825868}, {'name': 'Recall', 'type': 'recall', 'value': 0.8905194502678779}, {'name': 'F1', 'type': 'f1', 'value': 0.8843395789960676}, {'name': 'Accuracy', 'type': 'accuracy', 'value': 0.9476941505290477}]}\n"]}],"source":["if model_args.use_auth_token is not None:\n","    warnings.warn(\n","        \"The `use_auth_token` argument is deprecated and will be removed in v4.34. Please use `token` instead.\",\n","        FutureWarning,\n","    )\n","    if model_args.token is not None:\n","        raise ValueError(\"`token` and `use_auth_token` are both specified. Please set only the argument `token`.\")\n","    model_args.token = model_args.use_auth_token\n","\n","# Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n","# information sent is the one passed as arguments along with your Python/PyTorch versions.\n","send_example_telemetry(\"run_ner\", model_args, data_args)\n","\n","# Setup logging\n","logging.basicConfig(\n","    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n","    datefmt=\"%m/%d/%Y %H:%M:%S\",\n","    handlers=[logging.StreamHandler(sys.stdout)],\n",")\n","\n","if training_args.should_log:\n","    # The default of training_args.log_level is passive, so we set log level at info here to have that default.\n","    transformers.utils.logging.set_verbosity_info()\n","\n","log_level = training_args.get_process_log_level()\n","logger.setLevel(log_level)\n","datasets.utils.logging.set_verbosity(log_level)\n","transformers.utils.logging.set_verbosity(log_level)\n","transformers.utils.logging.enable_default_handler()\n","transformers.utils.logging.enable_explicit_format()\n","\n","# Log on each process the small summary:\n","logger.warning(\n","    f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}, \"\n","    + f\"distributed training: {training_args.parallel_mode.value == 'distributed'}, 16-bits training: {training_args.fp16}\"\n",")\n","logger.info(f\"Training/evaluation parameters {training_args}\")\n","\n","# Detecting last checkpoint.\n","last_checkpoint = None\n","if os.path.isdir(training_args.output_dir) and training_args.do_train and not training_args.overwrite_output_dir:\n","    last_checkpoint = get_last_checkpoint(training_args.output_dir)\n","    if last_checkpoint is None and len(os.listdir(training_args.output_dir)) > 0:\n","        raise ValueError(\n","            f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\n","            \"Use --overwrite_output_dir to overcome.\"\n","        )\n","    elif last_checkpoint is not None and training_args.resume_from_checkpoint is None:\n","        logger.info(\n","            f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"\n","            \"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"\n","        )\n","\n","# Set seed before initializing model.\n","set_seed(training_args.seed)\n","\n","# Get the datasets: you can either provide your own CSV/JSON/TXT training and evaluation files (see below)\n","# or just provide the name of one of the public datasets available on the hub at https://huggingface.co/datasets/\n","# (the dataset will be downloaded automatically from the datasets Hub).\n","#\n","# For CSV/JSON files, this script will use the column called 'text' or the first column if no column called\n","# 'text' is found. You can easily tweak this behavior (see below).\n","#\n","# In distributed training, the load_dataset function guarantee that only one local process can concurrently\n","# download the dataset.\n","if data_args.dataset_name is not None:\n","    # Downloading and loading a dataset from the hub.\n","    raw_datasets = load_dataset(\n","        data_args.dataset_name,\n","        data_args.dataset_config_name,\n","        cache_dir=model_args.cache_dir,\n","        token=model_args.token,\n","    )\n","else:\n","    data_files = {}\n","    if data_args.train_file is not None:\n","        data_files[\"train\"] = data_args.train_file\n","        extension = data_args.train_file.split(\".\")[-1]\n","\n","    if data_args.validation_file is not None:\n","        data_files[\"validation\"] = data_args.validation_file\n","        extension = data_args.validation_file.split(\".\")[-1]\n","    if data_args.test_file is not None:\n","        data_files[\"test\"] = data_args.test_file\n","        extension = data_args.test_file.split(\".\")[-1]\n","    raw_datasets = load_dataset(\n","        extension,\n","        data_files=data_files,\n","        cache_dir=model_args.cache_dir\n","        )\n","# See more about loading any type of standard or custom dataset (from files, python dict, pandas DataFrame, etc) at\n","# https://huggingface.co/docs/datasets/loading_datasets.\n","\n","if training_args.do_train:\n","    column_names = raw_datasets[\"train\"].column_names\n","    features = raw_datasets[\"train\"].features\n","else:\n","    column_names = raw_datasets[\"validation\"].column_names\n","    features = raw_datasets[\"validation\"].features\n","\n","if data_args.text_column_name is not None:\n","    text_column_name = data_args.text_column_name\n","elif \"tokens\" in column_names:\n","    text_column_name = \"tokens\"\n","else:\n","    text_column_name = column_names[0]\n","\n","if data_args.label_column_name is not None:\n","    label_column_name = data_args.label_column_name\n","elif f\"{data_args.task_name}_tags\" in column_names:\n","    label_column_name = f\"{data_args.task_name}_tags\"\n","else:\n","    label_column_name = column_names[1]\n","\n","# In the event the labels are not a `Sequence[ClassLabel]`, we will need to go through the dataset to get the\n","# unique labels.\n","def get_label_list(labels):\n","    unique_labels = set()\n","    for label in labels:\n","        unique_labels = unique_labels | set(label)\n","    label_list = list(unique_labels)\n","    label_list.sort()\n","    return label_list\n","\n","# If the labels are of type ClassLabel, they are already integers and we have the map stored somewhere.\n","# Otherwise, we have to get the list of labels manually.\n","\n","if data_args.dataset_name is not None: # Runs the following if using a Hugging Face DF\n","  labels_are_int = isinstance(features[label_column_name].feature, ClassLabel)\n","  if labels_are_int:\n","      label_list = features[label_column_name].feature.names\n","      label_to_id = {i: i for i in range(len(label_list))}\n","  else:\n","      label_list = get_label_list(raw_datasets[\"train\"][label_column_name])\n","      label_to_id = {l: i for i, l in enumerate(label_list)}\n","else: # Runs the following if using our own data\n","  # This is far from ideal but I'm tired of fighting it so I'm hard coding this in\n","  label_list = train_tag_scheme\n","  label_to_id = {l: i for i, l in enumerate(label_list)}\n","\n","num_labels = len(label_list)\n","\n","# Load pretrained model and tokenizer\n","#\n","# Distributed training:\n","# The .from_pretrained methods guarantee that only one local process can concurrently\n","# download model & vocab.\n","config = AutoConfig.from_pretrained(\n","    model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n","    num_labels=num_labels,\n","    finetuning_task=data_args.task_name,\n","    cache_dir=model_args.cache_dir,\n","    revision=model_args.model_revision,\n","    token=model_args.token,\n","    trust_remote_code=model_args.trust_remote_code,\n",")\n","\n","tokenizer_name_or_path = model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path\n","if config.model_type in {\"bloom\", \"gpt2\", \"roberta\"}:\n","    tokenizer = AutoTokenizer.from_pretrained(\n","        tokenizer_name_or_path,\n","        cache_dir=model_args.cache_dir,\n","        use_fast=True,\n","        revision=model_args.model_revision,\n","        token=model_args.token,\n","        trust_remote_code=model_args.trust_remote_code,\n","        add_prefix_space=True,\n","    )\n","else:\n","    tokenizer = AutoTokenizer.from_pretrained(\n","        tokenizer_name_or_path,\n","        cache_dir=model_args.cache_dir,\n","        use_fast=True,\n","        revision=model_args.model_revision,\n","        token=model_args.token,\n","        trust_remote_code=model_args.trust_remote_code,\n","    )\n","\n","model = RobertaForTokenClassification.from_pretrained(\n","  'roberta-base',\n","  config=config,\n","  cache_dir=model_args.cache_dir,\n",")\n","\n","\n","# Tokenizer check: this script requires a fast tokenizer.\n","if not isinstance(tokenizer, PreTrainedTokenizerFast):\n","    raise ValueError(\n","        \"This example script only works for models that have a fast tokenizer. Checkout the big table of models at\"\n","        \" https://huggingface.co/transformers/index.html#supported-frameworks to find the model types that meet\"\n","        \" this requirement\"\n","    )\n","\n","# Model has labels -> use them.\n","if model.config.label2id != PretrainedConfig(num_labels=num_labels).label2id:\n","    if sorted(model.config.label2id.keys()) == sorted(label_list):\n","        # Reorganize `label_list` to match the ordering of the model.\n","        if labels_are_int:\n","            label_to_id = {i: int(model.config.label2id[l]) for i, l in enumerate(label_list)}\n","            label_list = [model.config.id2label[i] for i in range(num_labels)]\n","        else:\n","            label_list = [model.config.id2label[i] for i in range(num_labels)]\n","            label_to_id = {l: i for i, l in enumerate(label_list)}\n","    else:\n","        logger.warning(\n","            \"Your model seems to have been trained with labels, but they don't match the dataset: \",\n","            f\"model labels: {sorted(model.config.label2id.keys())}, dataset labels:\"\n","            f\" {sorted(label_list)}.\\nIgnoring the model labels as a result.\",\n","        )\n","\n","# Set the correspondences label/ID inside the model config\n","model.config.label2id = {l: i for i, l in enumerate(label_list)}\n","model.config.id2label = dict(enumerate(label_list))\n","\n","# Map that sends B-Xxx label to its I-Xxx counterpart\n","b_to_i_label = []\n","for idx, label in enumerate(label_list):\n","    if label.startswith(\"B-\") and label.replace(\"B-\", \"I-\") in label_list:\n","        b_to_i_label.append(label_list.index(label.replace(\"B-\", \"I-\")))\n","    else:\n","        b_to_i_label.append(idx)\n","\n","# Preprocessing the dataset\n","# Padding strategy\n","padding = \"max_length\" if data_args.pad_to_max_length else False\n","\n","# Tokenize all texts and align the labels with them.\n","def tokenize_and_align_labels(examples):\n","    tokenized_inputs = tokenizer(\n","        examples[text_column_name],\n","        padding=padding,\n","        truncation=True,\n","        max_length=data_args.max_seq_length,\n","        # We use this argument because the texts in our dataset are lists of words (with a label for each word).\n","        is_split_into_words=True,\n","    )\n","    labels = []\n","    for i, label in enumerate(examples[label_column_name]):\n","        word_ids = tokenized_inputs.word_ids(batch_index=i)\n","        previous_word_idx = None\n","        label_ids = []\n","        for word_idx in word_ids:\n","            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n","            # ignored in the loss function.\n","            if word_idx is None:\n","                label_ids.append(-100)\n","            # We set the label for the first token of each word.\n","            elif word_idx != previous_word_idx:\n","                label_ids.append(label_to_id[label[word_idx]])\n","            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n","            # the label_all_tokens flag.\n","            else:\n","                if data_args.label_all_tokens:\n","                    label_ids.append(b_to_i_label[label_to_id[label[word_idx]]])\n","                else:\n","                    label_ids.append(-100)\n","            previous_word_idx = word_idx\n","\n","        labels.append(label_ids)\n","    tokenized_inputs[\"labels\"] = labels\n","    return tokenized_inputs\n","\n","if training_args.do_train:\n","    if \"train\" not in raw_datasets:\n","        raise ValueError(\"--do_train requires a train dataset\")\n","    train_dataset = raw_datasets[\"train\"]\n","    if data_args.max_train_samples is not None:\n","        max_train_samples = min(len(train_dataset), data_args.max_train_samples)\n","        train_dataset = train_dataset.select(range(max_train_samples))\n","    with training_args.main_process_first(desc=\"train dataset map pre-processing\"):\n","        train_dataset = train_dataset.map(\n","            tokenize_and_align_labels,\n","            batched=True,\n","            num_proc=data_args.preprocessing_num_workers,\n","            load_from_cache_file=not data_args.overwrite_cache,\n","            desc=\"Running tokenizer on train dataset\",\n","        )\n","\n","if training_args.do_eval:\n","    if \"validation\" not in raw_datasets:\n","        raise ValueError(\"--do_eval requires a validation dataset\")\n","    eval_dataset = raw_datasets[\"validation\"]\n","    if data_args.max_eval_samples is not None:\n","        max_eval_samples = min(len(eval_dataset), data_args.max_eval_samples)\n","        eval_dataset = eval_dataset.select(range(max_eval_samples))\n","    with training_args.main_process_first(desc=\"validation dataset map pre-processing\"):\n","        eval_dataset = eval_dataset.map(\n","            tokenize_and_align_labels,\n","            batched=True,\n","            num_proc=data_args.preprocessing_num_workers,\n","            load_from_cache_file=not data_args.overwrite_cache,\n","            desc=\"Running tokenizer on validation dataset\",\n","        )\n","\n","if training_args.do_predict:\n","    if \"test\" not in raw_datasets:\n","        raise ValueError(\"--do_predict requires a test dataset\")\n","    predict_dataset = raw_datasets[\"test\"]\n","    if data_args.max_predict_samples is not None:\n","        max_predict_samples = min(len(predict_dataset), data_args.max_predict_samples)\n","        predict_dataset = predict_dataset.select(range(max_predict_samples))\n","    with training_args.main_process_first(desc=\"prediction dataset map pre-processing\"):\n","        predict_dataset = predict_dataset.map(\n","            tokenize_and_align_labels,\n","            batched=True,\n","            num_proc=data_args.preprocessing_num_workers,\n","            load_from_cache_file=not data_args.overwrite_cache,\n","            desc=\"Running tokenizer on prediction dataset\",\n","        )\n","\n","# Data collator\n","data_collator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of=8 if training_args.fp16 else None)\n","\n","# Metrics\n","metric = evaluate.load(\"seqeval\", cache_dir=model_args.cache_dir)\n","\n","def compute_metrics(p):\n","    predictions, labels = p\n","    predictions = np.argmax(predictions, axis=2)\n","\n","    # Remove ignored index (special tokens)\n","    true_predictions = [\n","        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","    true_labels = [\n","        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","\n","    results = metric.compute(predictions=true_predictions, references=true_labels)\n","    if data_args.return_entity_level_metrics:\n","        # Unpack nested dictionaries\n","        final_results = {}\n","        for key, value in results.items():\n","            if isinstance(value, dict):\n","                for n, v in value.items():\n","                    final_results[f\"{key}_{n}\"] = v\n","            else:\n","                final_results[key] = value\n","        return final_results\n","    else:\n","        return {\n","            \"precision\": results[\"overall_precision\"],\n","            \"recall\": results[\"overall_recall\"],\n","            \"f1\": results[\"overall_f1\"],\n","            \"accuracy\": results[\"overall_accuracy\"],\n","        }\n","\n","# Initialize our Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset if training_args.do_train else None,\n","    eval_dataset=eval_dataset if training_args.do_eval else None,\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n","    callbacks=[metrics_logger],\n",")\n","\n","# Training\n","if training_args.do_train:\n","    checkpoint = None\n","    if training_args.resume_from_checkpoint is not None:\n","        checkpoint = training_args.resume_from_checkpoint\n","    elif last_checkpoint is not None:\n","        checkpoint = last_checkpoint\n","    train_result = trainer.train(resume_from_checkpoint=checkpoint)\n","    metrics = train_result.metrics\n","    trainer.save_model()  # Saves the tokenizer too for easy upload\n","\n","    max_train_samples = (\n","        data_args.max_train_samples if data_args.max_train_samples is not None else len(train_dataset)\n","    )\n","    metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n","\n","    trainer.log_metrics(\"train\", metrics)\n","    trainer.save_metrics(\"train\", metrics)\n","    trainer.save_state()\n","\n","# Evaluation\n","if training_args.do_eval:\n","    logger.info(\"*** Evaluate ***\")\n","\n","    metrics = trainer.evaluate()\n","\n","    max_eval_samples = data_args.max_eval_samples if data_args.max_eval_samples is not None else len(eval_dataset)\n","    metrics[\"eval_samples\"] = min(max_eval_samples, len(eval_dataset))\n","\n","    trainer.log_metrics(\"eval\", metrics)\n","    trainer.save_metrics(\"eval\", metrics)\n","\n","# Predict\n","if training_args.do_predict:\n","    logger.info(\"*** Predict ***\")\n","\n","    predictions, labels, metrics = trainer.predict(predict_dataset, metric_key_prefix=\"predict\")\n","    predictions = np.argmax(predictions, axis=2)\n","\n","    # Remove ignored index (special tokens)\n","    true_predictions = [\n","        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","\n","    trainer.log_metrics(\"predict\", metrics)\n","    trainer.save_metrics(\"predict\", metrics)\n","\n","    # Save predictions\n","    output_predictions_file = os.path.join(training_args.output_dir, \"predictions.txt\")\n","    if trainer.is_world_process_zero():\n","        with open(output_predictions_file, \"w\") as writer:\n","            for prediction in true_predictions:\n","                writer.write(\" \".join(prediction) + \"\\n\")\n","\n","kwargs = {\"finetuned_from\": model_args.model_name_or_path, \"tasks\": \"token-classification\"}\n","if data_args.dataset_name is not None:\n","    kwargs[\"dataset_tags\"] = data_args.dataset_name\n","    if data_args.dataset_config_name is not None:\n","        kwargs[\"dataset_args\"] = data_args.dataset_config_name\n","        kwargs[\"dataset\"] = f\"{data_args.dataset_name} {data_args.dataset_config_name}\"\n","    else:\n","        kwargs[\"dataset\"] = data_args.dataset_name\n","\n","if training_args.push_to_hub:\n","    trainer.push_to_hub(**kwargs)\n","else:\n","    trainer.create_model_card(**kwargs)\n","TRAINED_MODEL = model\n"]},{"cell_type":"markdown","metadata":{"id":"2whkQbPeZ6zI"},"source":["## Save Model Weights\n","For use in TDAPT\n","\n"]},{"cell_type":"code","source":["# Fetching Roberta specific weights\n","roberta_weights = {k: v for k, v in TRAINED_MODEL.state_dict().items() if k.startswith('roberta')}"],"metadata":{"id":"fIlI7sHxV-xn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.save(roberta_weights, output_path + '/ner_weights.pt') # These will always drop in the model output folder and use the same name"],"metadata":{"id":"WiboVmlxZAaE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"J9F1RuIPFyND"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"16nq_G0fn-Z5dXDvDuKNmtbgRtYFxujKP","timestamp":1712236929314},{"file_id":"1PQxl9bHrT02ZkfLlWdbbOxrlFZ-zDEop","timestamp":1710664142952}],"gpuType":"V100","toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"082457e0884646cd905c3014534acefe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dfbe687cde0e4e398f8e1d0e6e6ca8f5","IPY_MODEL_124e35e1a46640c38c06f22ab1181071","IPY_MODEL_1899ad40bc654c948dfcd2899ca24b04"],"layout":"IPY_MODEL_fcd826d5ab5847f598424213c2ad3cbc"}},"dfbe687cde0e4e398f8e1d0e6e6ca8f5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e9524d2889a4f2bbc20f72a6b47993c","placeholder":"​","style":"IPY_MODEL_378cf71c1ac948139462a77b0a6c37ee","value":"Generating train split: "}},"124e35e1a46640c38c06f22ab1181071":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_20bfbe0b37404e748dd026cf325fac38","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3a648572d6384bddac21784045e5b9a4","value":1}},"1899ad40bc654c948dfcd2899ca24b04":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_95007e02739849ae8323f97d1a5f92a8","placeholder":"​","style":"IPY_MODEL_869aebdec95e4b6ba1d0cf1decd43420","value":" 7820/0 [00:00&lt;00:00, 16700.22 examples/s]"}},"fcd826d5ab5847f598424213c2ad3cbc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e9524d2889a4f2bbc20f72a6b47993c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"378cf71c1ac948139462a77b0a6c37ee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"20bfbe0b37404e748dd026cf325fac38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"3a648572d6384bddac21784045e5b9a4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"95007e02739849ae8323f97d1a5f92a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"869aebdec95e4b6ba1d0cf1decd43420":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"40771489dd2e4cb383e8a12bf3962191":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2807e03ef07e45a585a516e0d548d62e","IPY_MODEL_6d38a48a05bf4b01949d4c11ca4b69e9","IPY_MODEL_e2b2b1a79dbe422390a71be4ce1adfa9"],"layout":"IPY_MODEL_65be8bd9a43044059d64f607519043f0"}},"2807e03ef07e45a585a516e0d548d62e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b68c762942f4686899c965c23b78759","placeholder":"​","style":"IPY_MODEL_445dd9b3776e4fbba35a282cc1d478c5","value":"Generating validation split: "}},"6d38a48a05bf4b01949d4c11ca4b69e9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_651d230a3f284ed6822002729f389c10","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_690c107f7e7341f0b3be275b9afedbc7","value":1}},"e2b2b1a79dbe422390a71be4ce1adfa9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3339bc2782bc4a13addb94c7bf1c28ea","placeholder":"​","style":"IPY_MODEL_51906c345a8b46d499f27165f18925ba","value":" 1955/0 [00:00&lt;00:00, 22419.99 examples/s]"}},"65be8bd9a43044059d64f607519043f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b68c762942f4686899c965c23b78759":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"445dd9b3776e4fbba35a282cc1d478c5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"651d230a3f284ed6822002729f389c10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"690c107f7e7341f0b3be275b9afedbc7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3339bc2782bc4a13addb94c7bf1c28ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51906c345a8b46d499f27165f18925ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ce0999a4af894029b57d65cb34194d14":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2ba0f2434e7c4410a48d788ec1e54dc7","IPY_MODEL_02ccdbda8e2046b2b7f8d0b05c354958","IPY_MODEL_0b52b9614339478a814e09b084aaa78c"],"layout":"IPY_MODEL_911f631f1c0f4d0ba5446f1d2a5afcc5"}},"2ba0f2434e7c4410a48d788ec1e54dc7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0dbbcd0d74d46ebbc30b488f3bdf454","placeholder":"​","style":"IPY_MODEL_99ce10237312484aaf4ee47e98407188","value":"Generating test split: "}},"02ccdbda8e2046b2b7f8d0b05c354958":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_862f4dff545d4c57bd739ef2ee4e1d79","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1047a4c5e18d445ab15759d78c25b10b","value":1}},"0b52b9614339478a814e09b084aaa78c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4d76fea3031429998c02ce8559315de","placeholder":"​","style":"IPY_MODEL_c1d55306e12e471aaaf44d994cc6a5da","value":" 2443/0 [00:00&lt;00:00, 30413.44 examples/s]"}},"911f631f1c0f4d0ba5446f1d2a5afcc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0dbbcd0d74d46ebbc30b488f3bdf454":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99ce10237312484aaf4ee47e98407188":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"862f4dff545d4c57bd739ef2ee4e1d79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"1047a4c5e18d445ab15759d78c25b10b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a4d76fea3031429998c02ce8559315de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1d55306e12e471aaaf44d994cc6a5da":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"66cec72637c540afafe33f115206e962":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_582830cff56c45a393c65ce5a6b77fb2","IPY_MODEL_3878dbe229ad407794a9d3b96e1859cc","IPY_MODEL_7e0b25ac74d945cf9e33603dc6660a95"],"layout":"IPY_MODEL_4a99ec99c7eb46f6b0a001394673a944"}},"582830cff56c45a393c65ce5a6b77fb2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4896d292316486e97d6a9622d23968c","placeholder":"​","style":"IPY_MODEL_0102ccded263475ba4190ff61675f179","value":"config.json: 100%"}},"3878dbe229ad407794a9d3b96e1859cc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ace490aa4b644c7480f46fd988a56592","max":481,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dcf4c01119c2416bbddf532032b2c4e0","value":481}},"7e0b25ac74d945cf9e33603dc6660a95":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd97c17a8aae47b68216fb5c2cda726e","placeholder":"​","style":"IPY_MODEL_f2c36897bc8d46069993619a4677d5af","value":" 481/481 [00:00&lt;00:00, 19.6kB/s]"}},"4a99ec99c7eb46f6b0a001394673a944":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4896d292316486e97d6a9622d23968c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0102ccded263475ba4190ff61675f179":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ace490aa4b644c7480f46fd988a56592":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dcf4c01119c2416bbddf532032b2c4e0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dd97c17a8aae47b68216fb5c2cda726e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2c36897bc8d46069993619a4677d5af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1016481749384e56aa44b860b64e1087":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e0960b9000584fe0906874b3ac34a9bf","IPY_MODEL_9e9b75201303442381bc052afcbed30f","IPY_MODEL_dccc43aa74044afc81553a0d50522e17"],"layout":"IPY_MODEL_960f06cc99ad4f92b655bd8d8fc3809a"}},"e0960b9000584fe0906874b3ac34a9bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e60bfedf8b60495890712fff01a90843","placeholder":"​","style":"IPY_MODEL_5b4ed21512ed4e9a8418aa6cd9fda017","value":"tokenizer_config.json: 100%"}},"9e9b75201303442381bc052afcbed30f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c60e4b20156d404cac5cde724c5f45e5","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d37099d2dea24db4acc3ea3645c14d27","value":25}},"dccc43aa74044afc81553a0d50522e17":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b707363cbf4d4624b835c5781f2382f5","placeholder":"​","style":"IPY_MODEL_f40341b8a14a4d6ca15a02a96c80c93c","value":" 25.0/25.0 [00:00&lt;00:00, 686B/s]"}},"960f06cc99ad4f92b655bd8d8fc3809a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e60bfedf8b60495890712fff01a90843":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b4ed21512ed4e9a8418aa6cd9fda017":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c60e4b20156d404cac5cde724c5f45e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d37099d2dea24db4acc3ea3645c14d27":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b707363cbf4d4624b835c5781f2382f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f40341b8a14a4d6ca15a02a96c80c93c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68120606909444729e7d140c1b4e64d3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d5008726888042d6a55a9b58fa4e22d9","IPY_MODEL_81cee552cc9645dfb3299592c94b8b07","IPY_MODEL_7d71c00ba42c41e789e3c21fdb13afb6"],"layout":"IPY_MODEL_821147a0590c44dfa8e91d18a6cb3a36"}},"d5008726888042d6a55a9b58fa4e22d9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4d9e21a86464aacad34b3eee281d884","placeholder":"​","style":"IPY_MODEL_bc620cbb420d4a19b099224d7cdc1bd0","value":"vocab.json: 100%"}},"81cee552cc9645dfb3299592c94b8b07":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4bc0037a9be9424d8324938adb9db32e","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6a42e42aea144f0888d4f6b68e9712fd","value":898823}},"7d71c00ba42c41e789e3c21fdb13afb6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d6795cfa1bd4f2fb06a96047539c4dc","placeholder":"​","style":"IPY_MODEL_780f54a584194eab8de7ed959fa13138","value":" 899k/899k [00:00&lt;00:00, 10.2MB/s]"}},"821147a0590c44dfa8e91d18a6cb3a36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4d9e21a86464aacad34b3eee281d884":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc620cbb420d4a19b099224d7cdc1bd0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4bc0037a9be9424d8324938adb9db32e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a42e42aea144f0888d4f6b68e9712fd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5d6795cfa1bd4f2fb06a96047539c4dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"780f54a584194eab8de7ed959fa13138":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"14298011c9354338b1ae7d643d73de31":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_163324e96bea4d2dbe61c0b239b9d0cc","IPY_MODEL_f8d5c56dbd3a4b998aa8bca5353a1ca2","IPY_MODEL_0a8ac9f5b7004a5bbcdad5da17eee7d4"],"layout":"IPY_MODEL_b624dc3952b540ab81588c5c447183e9"}},"163324e96bea4d2dbe61c0b239b9d0cc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_68c35d7a8c2847909be08761478d0afc","placeholder":"​","style":"IPY_MODEL_1e9a3b7cc3d643b3a91e74d92798295b","value":"merges.txt: 100%"}},"f8d5c56dbd3a4b998aa8bca5353a1ca2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_934cf611e13e4af38d12d1c114687dae","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fc83fcf57cd74143a23f29d50de3dc69","value":456318}},"0a8ac9f5b7004a5bbcdad5da17eee7d4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e8749bd686449f4a00dea803d716ee7","placeholder":"​","style":"IPY_MODEL_4e13093b938d42e6874f45eee06bdacd","value":" 456k/456k [00:00&lt;00:00, 2.82MB/s]"}},"b624dc3952b540ab81588c5c447183e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68c35d7a8c2847909be08761478d0afc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e9a3b7cc3d643b3a91e74d92798295b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"934cf611e13e4af38d12d1c114687dae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc83fcf57cd74143a23f29d50de3dc69":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0e8749bd686449f4a00dea803d716ee7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e13093b938d42e6874f45eee06bdacd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"06b860467fda4a39b2176e5477ef2bdb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d8f098a9411b446280c3e5cfadb8447c","IPY_MODEL_235b49a27c614e1c91820762e7bf809f","IPY_MODEL_c0c13caf751e45b29e8c2a0e8ec6cec1"],"layout":"IPY_MODEL_cbc8285dd43a412098b0eab24d445454"}},"d8f098a9411b446280c3e5cfadb8447c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_318fd4943741427f972e4707a12ac7bb","placeholder":"​","style":"IPY_MODEL_0f7cce8d7a144e46ba60a010cb2ce179","value":"tokenizer.json: 100%"}},"235b49a27c614e1c91820762e7bf809f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4985cab45c244e378833e1b6bf8ef770","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_54d43fbbb90d48ea87f1486f9be8aac0","value":1355863}},"c0c13caf751e45b29e8c2a0e8ec6cec1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8eec0e1abdff4474aa08eb594ca02e46","placeholder":"​","style":"IPY_MODEL_e759f65a04eb44eeb86753a650042b06","value":" 1.36M/1.36M [00:00&lt;00:00, 8.07MB/s]"}},"cbc8285dd43a412098b0eab24d445454":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"318fd4943741427f972e4707a12ac7bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f7cce8d7a144e46ba60a010cb2ce179":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4985cab45c244e378833e1b6bf8ef770":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54d43fbbb90d48ea87f1486f9be8aac0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8eec0e1abdff4474aa08eb594ca02e46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e759f65a04eb44eeb86753a650042b06":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31a11a618312458d8d03c1609f3aa776":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2353b733a38a4fefa6934f65c52a9b84","IPY_MODEL_702fa9e502564b5eb343c975fbd802d6","IPY_MODEL_0130d29a317c41d6905aedb91a134153"],"layout":"IPY_MODEL_17f474fca3bc471e97cf1d6c72c2bdef"}},"2353b733a38a4fefa6934f65c52a9b84":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_32f7d5e75fc1464dbcec68d3e3a2ec51","placeholder":"​","style":"IPY_MODEL_980565427bf143048f62e536919599ae","value":"model.safetensors: 100%"}},"702fa9e502564b5eb343c975fbd802d6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e37e2620c6f94a418dc8183f1f3a3302","max":498818054,"min":0,"orientation":"horizontal","style":"IPY_MODEL_009b9816f7884498a86b80e1e03b1a12","value":498818054}},"0130d29a317c41d6905aedb91a134153":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b232aa7f45474028bd25c0ad649b68e8","placeholder":"​","style":"IPY_MODEL_362fbfc9814c48cba88419167fe7546c","value":" 499M/499M [00:04&lt;00:00, 72.5MB/s]"}},"17f474fca3bc471e97cf1d6c72c2bdef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32f7d5e75fc1464dbcec68d3e3a2ec51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"980565427bf143048f62e536919599ae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e37e2620c6f94a418dc8183f1f3a3302":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"009b9816f7884498a86b80e1e03b1a12":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b232aa7f45474028bd25c0ad649b68e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"362fbfc9814c48cba88419167fe7546c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aabf116a3fa24708b8f5ac08609d66a5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5311913692fa4841a718cb71312c9442","IPY_MODEL_0481097551e14e20b37d0ed1ea9f8618","IPY_MODEL_0ca3542ce6134396bb9bdf1c37537ba1"],"layout":"IPY_MODEL_46408c166b7941da9cdd8249d0d8dd65"}},"5311913692fa4841a718cb71312c9442":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec8d68d483de4c7a9b6b2ba7c75b00da","placeholder":"​","style":"IPY_MODEL_4ac2c87c208044c19009728ee9ae3244","value":"Running tokenizer on train dataset: 100%"}},"0481097551e14e20b37d0ed1ea9f8618":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_45f9d3901e304b3693257eb9a818b91c","max":7820,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0bfd420ce5f94fe5b42747bdd6c4621e","value":7820}},"0ca3542ce6134396bb9bdf1c37537ba1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_264ef242d25f4cf4afb6739bb4133612","placeholder":"​","style":"IPY_MODEL_095429075ba34721823e7e470a25ca2e","value":" 7820/7820 [00:02&lt;00:00, 4319.27 examples/s]"}},"46408c166b7941da9cdd8249d0d8dd65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec8d68d483de4c7a9b6b2ba7c75b00da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ac2c87c208044c19009728ee9ae3244":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"45f9d3901e304b3693257eb9a818b91c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0bfd420ce5f94fe5b42747bdd6c4621e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"264ef242d25f4cf4afb6739bb4133612":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"095429075ba34721823e7e470a25ca2e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1a1c7f856b554ced847db56833362a60":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bb488b3ebbc446dba28d835841c71e2f","IPY_MODEL_491b7fcc91c043c1b86991b6fb04b061","IPY_MODEL_f37bd178d0de472589b1c91edc5d4a9c"],"layout":"IPY_MODEL_f7809024647d4bf3a591f27bd96eea32"}},"bb488b3ebbc446dba28d835841c71e2f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ea48551b835452bb9994164414bab0c","placeholder":"​","style":"IPY_MODEL_126b178349ae4fd39255a964ef5e6bc9","value":"Running tokenizer on validation dataset: 100%"}},"491b7fcc91c043c1b86991b6fb04b061":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8d6255f54d54e2eb349391b8428d207","max":1955,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f0fc81af3ffc46ec9c4238b61d6a13ba","value":1955}},"f37bd178d0de472589b1c91edc5d4a9c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_67ee6ef1f9b9440e8736e2750c7c00c4","placeholder":"​","style":"IPY_MODEL_b0114c37a4864bad897aa5bfbf1993a4","value":" 1955/1955 [00:00&lt;00:00, 4875.22 examples/s]"}},"f7809024647d4bf3a591f27bd96eea32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ea48551b835452bb9994164414bab0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"126b178349ae4fd39255a964ef5e6bc9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d8d6255f54d54e2eb349391b8428d207":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0fc81af3ffc46ec9c4238b61d6a13ba":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"67ee6ef1f9b9440e8736e2750c7c00c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0114c37a4864bad897aa5bfbf1993a4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"51e7f26907794de2b5935416b9f7deb3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_47c688c96fee47a4aa8eddb2c6b67f8f","IPY_MODEL_8ed46f4368fb4291853077f25d829cae","IPY_MODEL_b447c176e5eb451391dab57418cd000d"],"layout":"IPY_MODEL_867aa84be3cd4027b271f5d75143be3b"}},"47c688c96fee47a4aa8eddb2c6b67f8f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6edd1f360314504bfe60cb8d31b3a5b","placeholder":"​","style":"IPY_MODEL_2d26e159560e4606bd846952114b999a","value":"Downloading builder script: 100%"}},"8ed46f4368fb4291853077f25d829cae":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca8711bc74ff4aafa08225ff0836fb6b","max":6338,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a2d29c5166bc48e8b0b3bae17fc2914d","value":6338}},"b447c176e5eb451391dab57418cd000d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_612225d3982342718398633e008921bc","placeholder":"​","style":"IPY_MODEL_8d140318a3b848df94fb20b795529456","value":" 6.34k/6.34k [00:00&lt;00:00, 233kB/s]"}},"867aa84be3cd4027b271f5d75143be3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6edd1f360314504bfe60cb8d31b3a5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d26e159560e4606bd846952114b999a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ca8711bc74ff4aafa08225ff0836fb6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2d29c5166bc48e8b0b3bae17fc2914d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"612225d3982342718398633e008921bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d140318a3b848df94fb20b795529456":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}