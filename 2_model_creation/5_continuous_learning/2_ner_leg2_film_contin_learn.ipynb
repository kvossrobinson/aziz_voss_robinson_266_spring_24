{"cells":[{"cell_type":"markdown","source":["# README\n","\n","**Purpose**\n","\n","Fine tune the pre-trained HuggingFace RoBERTa base on domain-specific NER with the dataset of your choice\n","\n","**How-To**\n","\n","Make any updates in the \"Update Each Run\" section before running all cells. Places to take particular care:\n","\n","\n","*   output_model - If you forget to change this and have overwrite set to True, you will erase whatever was previously in the folder.\n","*   overwrite - This must be set to False if you are training from a checkpoint.\n","*   name - I'm not sure this is getting used, but I've been updating it anyway.\n","\n"],"metadata":{"id":"RBt0eAlgBMu2"}},{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"bPnMEvC_9HEz"}},{"cell_type":"markdown","source":["## Will Need Regular Changes"],"metadata":{"id":"66H42RDz9Hfa"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"UK37MFQN2rxO"},"outputs":[],"source":["## Custom Model\n","\n","# Path to get NER weights to import # Only the first bit should need updates - make it the folder of the NER model you just made\n","ner_weights_path = '/content/drive/My Drive/266/experiments/models/4_7__5_1_contin_learn_ner_b/' + 'ner_weights.pt'\n","\n","## Training Args\n","\n","# Where to put the model outputs\n","output_path = '/content/drive/MyDrive/266/experiments/models/4_7__5_2_contin_learn_ner_b_m'\n","\n","# Are you training?\n","do_train_flag = True\n","\n","# Are you evaluating?\n","do_eval_flag = True\n","\n","# Number of train epochs\n","epoch_count = 2\n","\n","# Number of save steps\n","save_step_count = 1000\n","\n","# Number of eval steps\n","eval_step_count = 1000 # Keep same as logging_steps\n","\n","# Number of logging steps\n","logging_step_count = eval_step_count # Keep same as logging_steps\n","\n","# Overwrite Output Dir - MUST be False if you're training from a checkpoint\n","overwrite = True\n","\n","# Run Name\n","name = '2 epoch NER with continual learning - biomedical and movies'"]},{"cell_type":"markdown","source":["## Will *Not* Need Regular Changes"],"metadata":{"id":"7TIABThw9H_x"}},{"cell_type":"code","source":["## Data Args - Not actually getting used, but leaving anyway to avoid bugs\n","\n","# Path to get the domain-specific NER data\n","data_path = '/content/drive/My Drive/266/source_of_truth/data/'\n","\n","## Preprocessing within Main\n","train_tag_scheme = ['B-ACTOR',\n","                    'B-CHARACTER',\n","                    'B-DIRECTOR',\n","                    'B-GENRE',\n","                    'B-PLOT',\n","                    'B-RATING',\n","                    'B-RATINGS_AVERAGE',\n","                    'B-REVIEW',\n","                    'B-SONG',\n","                    'B-TITLE',\n","                    'B-TRAILER',\n","                    'B-YEAR',\n","                    'I-ACTOR',\n","                    'I-CHARACTER',\n","                    'I-DIRECTOR',\n","                    'I-GENRE',\n","                    'I-PLOT',\n","                    'I-RATING',\n","                    'I-RATINGS_AVERAGE',\n","                    'I-REVIEW',\n","                    'I-SONG',\n","                    'I-TITLE',\n","                    'I-TRAILER',\n","                    'I-YEAR',\n","                    'O']"],"metadata":{"id":"WNAamZD1_-pA"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jnfsWsXvRKXA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712624599924,"user_tz":300,"elapsed":23984,"user":{"displayName":"Katherine Voss-Robinson","userId":"10124239414397994450"}},"outputId":"1500a3f8-b1bc-4e7c-df62-934204e47042"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i9dp9sY4Tgtf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712625266797,"user_tz":300,"elapsed":666877,"user":{"displayName":"Katherine Voss-Robinson","userId":"10124239414397994450"}},"outputId":"9060649d-6764-4738-c23b-2f8425a56ddc"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m649.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m927.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m680.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m633.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.3/297.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m813.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install -q evaluate\n","!pip install -q datasets\n","!pip install -q accelerate -U\n","!pip install -q seqeval"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0taF9kX5RTXM"},"outputs":[],"source":["import logging\n","import os\n","import sys\n","import warnings\n","from dataclasses import dataclass, field\n","from typing import Optional, Tuple, Union, List, Dict\n","\n","import datasets\n","import evaluate\n","import numpy as np\n","from datasets import ClassLabel, load_dataset\n","\n","import transformers\n","from transformers import (\n","    AutoConfig,\n","    AutoModelForTokenClassification,\n","    AutoTokenizer,\n","    DataCollatorForTokenClassification,\n","    HfArgumentParser,\n","    PretrainedConfig,\n","    PreTrainedTokenizerFast,\n","    Trainer,\n","    TrainingArguments,\n","    set_seed,\n","    RobertaPreTrainedModel, RobertaModel, RobertaConfig\n",")\n","from transformers.trainer_utils import get_last_checkpoint\n","from transformers.utils import check_min_version, send_example_telemetry, ModelOutput\n","from transformers.utils.versions import require_version\n","\n","import torch\n","import torch.utils.checkpoint\n","from torch import nn\n","from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss"]},{"cell_type":"markdown","source":["# Custom Model"],"metadata":{"id":"AV2YxQVKEh6r"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5DeDuN5DT2yU"},"outputs":[],"source":["@dataclass\n","class TokenClassifierOutput(ModelOutput):\n","    \"\"\"\n","    Base class for outputs of token classification models.\n","\n","    Args:\n","        loss (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels` is provided) :\n","            Classification loss.\n","        logits (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.num_labels)`):\n","            Classification scores (before SoftMax).\n","        hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`):\n","            Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model has an embedding layer, +\n","            one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.\n","\n","            Hidden-states of the model at the output of each layer plus the optional initial embedding outputs.\n","        attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`):\n","            Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length,\n","            sequence_length)`.\n","\n","            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n","            heads.\n","    \"\"\"\n","\n","    loss: Optional[torch.FloatTensor] = None\n","    logits: torch.FloatTensor = None\n","    hidden_states: Optional[Tuple[torch.FloatTensor, ...]] = None\n","    attentions: Optional[Tuple[torch.FloatTensor, ...]] = None\n","\n","class RobertaForTokenClassification(RobertaPreTrainedModel):\n","    def __init__(self, config):\n","        super().__init__(config)\n","        self.num_labels = config.num_labels\n","\n","        self.roberta = RobertaModel(config, add_pooling_layer=False)\n","        classifier_dropout = (\n","            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n","        )\n","        self.dropout = nn.Dropout(classifier_dropout)\n","        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n","\n","        # Importing weights from prior NER\n","        pre_trained_weights = torch.load(ner_weights_path)\n","        adjusted_pre_trained_weights = {key.replace(\"roberta.\", \"\"): value for key, value in pre_trained_weights.items()}\n","        self.roberta.load_state_dict(adjusted_pre_trained_weights)\n","        # Initialize weights and apply final processing\n","\n","        # Initialize weights and apply final processing\n","        self.post_init()\n","\n","    def forward(\n","        self,\n","        input_ids: Optional[torch.LongTensor] = None,\n","        attention_mask: Optional[torch.FloatTensor] = None,\n","        token_type_ids: Optional[torch.LongTensor] = None,\n","        position_ids: Optional[torch.LongTensor] = None,\n","        head_mask: Optional[torch.FloatTensor] = None,\n","        inputs_embeds: Optional[torch.FloatTensor] = None,\n","        labels: Optional[torch.LongTensor] = None,\n","        output_attentions: Optional[bool] = None,\n","        output_hidden_states: Optional[bool] = None,\n","        return_dict: Optional[bool] = None,\n","    ) -> Union[Tuple[torch.Tensor], TokenClassifierOutput]:\n","        r\"\"\"\n","        labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n","            Labels for computing the token classification loss. Indices should be in `[0, ..., config.num_labels - 1]`.\n","        \"\"\"\n","        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","\n","        outputs = self.roberta(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=token_type_ids,\n","            position_ids=position_ids,\n","            head_mask=head_mask,\n","            inputs_embeds=inputs_embeds,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,\n","        )\n","\n","        sequence_output = outputs[0]\n","\n","        sequence_output = self.dropout(sequence_output)\n","        logits = self.classifier(sequence_output)\n","\n","        loss = None\n","        if labels is not None:\n","            # move labels to correct device to enable model parallelism\n","            labels = labels.to(logits.device)\n","            loss_fct = CrossEntropyLoss()\n","            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n","\n","        if not return_dict:\n","          output = (logits,) + outputs[2:]\n","          return ((loss,) + output) if loss is not None else output\n","\n","        return TokenClassifierOutput(\n","            loss=loss,\n","            logits=logits,\n","            hidden_states=outputs.hidden_states,\n","            attentions=outputs.attentions,\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-QVmnfY_T-0s"},"outputs":[],"source":["# Setting logger\n","logger = logging.getLogger(__name__)\n","TRAINED_MODEL = None"]},{"cell_type":"markdown","metadata":{"id":"TYxaK6knRUGj"},"source":["# Classes"]},{"cell_type":"markdown","source":["## MetricsLogger"],"metadata":{"id":"OI5VOF0e9cvu"}},{"cell_type":"code","source":["from transformers import TrainerCallback\n","\n","class MetricsLogger(TrainerCallback):\n","    \"A logger that will store metrics after each evaluation.\"\n","    def __init__(self):\n","        self.metrics = []\n","\n","    def on_log(self, args, state, control, logs=None, **kwargs):\n","        if logs is not None:\n","            # You can add more metrics here if needed\n","            self.metrics.append({\n","                \"step\": state.global_step,\n","                \"loss\": logs.get(\"loss\", None),\n","                \"eval_loss\": logs.get(\"eval_loss\", None),\n","            })\n","\n","# Initialize your logger\n","metrics_logger = MetricsLogger()\n"],"metadata":{"id":"XHoSARQ8ttLz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## ModelArguments"],"metadata":{"id":"RfWh61M99e19"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"0wx7lqvRRUOP"},"outputs":[],"source":["@dataclass\n","class ModelArguments:\n","    \"\"\"\n","    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n","    \"\"\"\n","\n","    model_name_or_path: str = field(\n","        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n","    )\n","    config_name: Optional[str] = field(\n","        default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n","    )\n","    tokenizer_name: Optional[str] = field(\n","        default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n","    )\n","    cache_dir: Optional[str] = field(\n","        default=None,\n","        metadata={\"help\": \"Where do you want to store the pretrained models downloaded from huggingface.co\"},\n","    )\n","    model_revision: str = field(\n","        default=\"main\",\n","        metadata={\"help\": \"The specific model version to use (can be a branch name, tag name or commit id).\"},\n","    )\n","    token: str = field(\n","        default=None,\n","        metadata={\n","            \"help\": (\n","                \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n","                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n","            )\n","        },\n","    )\n","    use_auth_token: bool = field(\n","        default=None,\n","        metadata={\n","            \"help\": \"The `use_auth_token` argument is deprecated and will be removed in v4.34. Please use `token` instead.\"\n","        },\n","    )\n","    trust_remote_code: bool = field(\n","        default=False,\n","        metadata={\n","            \"help\": (\n","                \"Whether or not to allow for custom models defined on the Hub in their own modeling files. This option \"\n","                \"should only be set to `True` for repositories you trust and in which you have read the code, as it will \"\n","                \"execute code present on the Hub on your local machine.\"\n","            )\n","        },\n","    )\n","    ignore_mismatched_sizes: bool = field(\n","        default=False,\n","        metadata={\"help\": \"Will enable to load a pretrained model whose head dimensions are different.\"},\n","    )"]},{"cell_type":"markdown","source":["## DataTrainingArguments"],"metadata":{"id":"cVig-fx89ghX"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"GXPu2alXUI0Y"},"outputs":[],"source":["@dataclass\n","class DataTrainingArguments:\n","    \"\"\"\n","    Arguments pertaining to what data we are going to input our model for training and eval.\n","    \"\"\"\n","\n","    task_name: Optional[str] = field(default=\"ner\", metadata={\"help\": \"The name of the task (ner, pos...).\"})\n","    dataset_name: Optional[str] = field(\n","        default=None, metadata={\"help\": \"The name of the dataset to use (via the datasets library).\"}\n","    )\n","    dataset_config_name: Optional[str] = field(\n","        default=None, metadata={\"help\": \"The configuration name of the dataset to use (via the datasets library).\"}\n","    )\n","    train_file: Optional[str] = field(\n","        default=None, metadata={\"help\": \"The input training data file (a csv or JSON file).\"}\n","    )\n","    validation_file: Optional[str] = field(\n","        default=None,\n","        metadata={\"help\": \"An optional input evaluation data file to evaluate on (a csv or JSON file).\"},\n","    )\n","    test_file: Optional[str] = field(\n","        default=None,\n","        metadata={\"help\": \"An optional input test data file to predict on (a csv or JSON file).\"},\n","    )\n","    text_column_name: Optional[str] = field(\n","        default=None, metadata={\"help\": \"The column name of text to input in the file (a csv or JSON file).\"}\n","    )\n","    label_column_name: Optional[str] = field(\n","        default=None, metadata={\"help\": \"The column name of label to input in the file (a csv or JSON file).\"}\n","    )\n","    overwrite_cache: bool = field(\n","        default=False, metadata={\"help\": \"Overwrite the cached training and evaluation sets\"}\n","    )\n","    preprocessing_num_workers: Optional[int] = field(\n","        default=None,\n","        metadata={\"help\": \"The number of processes to use for the preprocessing.\"},\n","    )\n","    max_seq_length: int = field(\n","        default=None,\n","        metadata={\n","            \"help\": (\n","                \"The maximum total input sequence length after tokenization. If set, sequences longer \"\n","                \"than this will be truncated, sequences shorter will be padded.\"\n","            )\n","        },\n","    )\n","    pad_to_max_length: bool = field(\n","        default=False,\n","        metadata={\n","            \"help\": (\n","                \"Whether to pad all samples to model maximum sentence length. \"\n","                \"If False, will pad the samples dynamically when batching to the maximum length in the batch. More \"\n","                \"efficient on GPU but very bad for TPU.\"\n","            )\n","        },\n","    )\n","    max_train_samples: Optional[int] = field(\n","        default=None,\n","        metadata={\n","            \"help\": (\n","                \"For debugging purposes or quicker training, truncate the number of training examples to this \"\n","                \"value if set.\"\n","            )\n","        },\n","    )\n","    max_eval_samples: Optional[int] = field(\n","        default=None,\n","        metadata={\n","            \"help\": (\n","                \"For debugging purposes or quicker training, truncate the number of evaluation examples to this \"\n","                \"value if set.\"\n","            )\n","        },\n","    )\n","    max_predict_samples: Optional[int] = field(\n","        default=None,\n","        metadata={\n","            \"help\": (\n","                \"For debugging purposes or quicker training, truncate the number of prediction examples to this \"\n","                \"value if set.\"\n","            )\n","        },\n","    )\n","    label_all_tokens: bool = field(\n","        default=False,\n","        metadata={\n","            \"help\": (\n","                \"Whether to put the label for one word on all tokens of generated by that word or just on the \"\n","                \"one (in which case the other tokens will have a padding index).\"\n","            )\n","        },\n","    )\n","    return_entity_level_metrics: bool = field(\n","        default=False,\n","        metadata={\"help\": \"Whether to return all the entity levels during evaluation or just the overall ones.\"},\n","    )\n","\n","    def __post_init__(self):\n","        if self.dataset_name is None and self.train_file is None and self.validation_file is None:\n","            raise ValueError(\"Need either a dataset name or a training/validation file.\")\n","        else:\n","            if self.train_file is not None:\n","                extension = self.train_file.split(\".\")[-1]\n","                assert extension in [\"csv\", \"json\"], \"`train_file` should be a csv or a json file.\"\n","            if self.validation_file is not None:\n","                extension = self.validation_file.split(\".\")[-1]\n","                assert extension in [\"csv\", \"json\"], \"`validation_file` should be a csv or a json file.\"\n","        self.task_name = self.task_name.lower()"]},{"cell_type":"markdown","metadata":{"id":"UPrbWKuIRU65"},"source":["# Main"]},{"cell_type":"markdown","metadata":{"id":"ba67RcGQRVIC"},"source":["## Creating Args"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4EowQUcAVOzJ"},"outputs":[],"source":["# Creating instances of the three required classes\n","\n","model_args = ModelArguments(model_name_or_path = \"roberta-base\")\n","\n","data_args = DataTrainingArguments(train_file = data_path + 'plain_training.json',\n","                                  validation_file = data_path + 'plain_val.json',\n","                                  test_file = data_path + 'plain_test.json',\n","                                  max_seq_length = 384,\n","                                  overwrite_cache = True\n","                                  )\n","\n","training_args = TrainingArguments(output_dir = output_path,\n","                                  do_train = do_train_flag,\n","                                  do_eval = do_eval_flag,\n","                                  num_train_epochs = epoch_count,\n","                                  save_strategy = \"epoch\",\n","                                  evaluation_strategy = \"epoch\",\n","                                  save_total_limit = 2,\n","                                  per_device_train_batch_size = 16,\n","                                  per_device_eval_batch_size = 10,\n","                                  overwrite_output_dir = overwrite,\n","                                  run_name = name\n","                                  )"]},{"cell_type":"markdown","metadata":{"id":"qUtQfOn4RVWC"},"source":["## Training the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SzzG5hM-RVc4","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["dbb1c8811c4d4d9fa2e4fb292836a323","fb3701fa799e4eb4b43c6bfd22c0a15f","2ce42f59ec0e4b6b992276ae56d369e3","bbb5346c4afb4df2a98783fdb1805985","788fa5f4ce2d4c88ad1b5d6dbc0336c8","a8302db96cbd4a1685b33e540d17b6e1","5dae9c6b7f3e4a10be0a3dbf56963749","c7ee75ead4a9408b9a010c4b6b94a8a6","30be6b1eb4324429ac6524350c72af53","78140dbb088f48bd9d86e1e9781f21bf","40f75f206ff44b1fb1615d904b8457ea","84d935590d8f435c9f1983097bb6d76f","5891b70f75fb489e9ac1a68f61031891","5c8fc6acb7e34bf58fa45c1e2c48c437","b3b24312fc0640bc8a94fe376d51fb21","7f399cb4ef234738a78a5bb5952ab680","dcdb3706d5df4ea18395c4d401e3bbf2","129f0b5d67f8468399749cfd31708fb2","fb6b0bb24bff4eff91bf097c950db89d","bdbecbd96e8845d6bc079041794af0b5","527672a9e35c47958a03adca021056b7","220c2462b2d54b1383e54f96c19d90eb","e56cc827f5fa4b2c918c1c87cd7ebe2b","e301e0a04534462ebdd130f254c02886","38417de0008243c48f0243614462ffa9","2159399cfabc4c9988f8cc4dc0098748","773741643c3045c981ce86aec8a330bf","73b89b71afab42a5b2496cf2628f8838","2edd187ecfc0480faecfd03e1c34f5bd","c60c303480ee4e2ea29355a9968e103f","aee32518e33a4cb4b197fe8a27017a03","a7ff3fa532914a0385ecf1ab45462f2b","82070506e9bd48128b0325d4c7301a61","579c7aff994c426487c4d6523c47e707","de0022725cc44e6cbb559182cbd13c65","a107ffe78a7a4dd0b71d10f371dfcb07","5e231ac7252041f79b274ccf747ac43f","e233131b378d40bf8c70ed16e816c578","ff66bce20c9f419d836d90a3fdd3fc6d","67fecfc1c6184df18af53ced1d197f92","3d99b98c64b147a087cb2080df03bea9","a0349fc25ea94ac6a86cfefaa0633cbc","2a52384fedb5474bab862aa0af9ad484","2467796e21654844bc26dd1ad99a8bf9","a074b6d1b066458f99ae87f033193957","9bc28df4b90e48e99e76f4881842f852","5d822ba8887b4c49b36b60cce1b7bbee","54aead456ce74ba6894173056339ff95","946c942892784411998fc60a44facdad","1dafdec8d3554d3bb3cb8debb585fcc3","341c9f6f03c04591b3e51c6236745c3a","5ff3e506650c4d269a80115741ff6bdc","25e7cc8ba310432c8c249f44c87de7a1","2fb95822a3b64cdcbcee256158793c93","9f15c6d9a9cb4901b3782a60f5a3897c","2b61046b77284b3dbbd1c9d3411f69a7","9a0444d37f74460fbad02e25bf99642e","3e5db8b6f6c6497283c4056514bac88d","c2fe116f3d504748892700f63ba071f8","23343f15e2cb4458a49606c175466871","fd4e23e85622452489f5b416f2b47f68","cecf7b274ab34664a6a8b41ac0ba7c24","50b4d752b5f8452f845f92636efef08f","f17fa467e68e4742ac95e494676173f5","3ff7807fe7874d88baa3e6c4f2a66d7d","ebee364c2e9a4c06a0809e07d7b5d559","3f445f33b9cf498ea18d7b303105eab8","955425e66d414da78b8ca8a78b4f2c1d","526dad9b97524e8d990cbe7c3d443d0b","79552df9b0d246129e05d4ed064f31c1","f15bb8f5fba64e18878fcac51b3758b5","bd76665db88541aeae156b2f9704d3de","eaf0772361bd430ab528b38318f2aaa2","09c9a08722f143bea42ceed3d65ee4f1","6c9cbed4a0b847b3b88de96b112fc6d1","e7e16f03c8f741e689b82cfbac39900d","488f0d7735e542a9998edd4618a8af49","8039d153c3a24bab91cbcbff03713ae1","c3606e06352142afbf858d1714cb003a","2d0649ecddb840a6b8c02adf87af6b36","f4a07e1c616a47c0b0bd81c27a69db7b","4da93c28901447dcaa44589a2cfdac1c","c4201e72588d43369e014a9569959d16","709b895eaa3247fca88119591b2e6893","03162ce3adbc488aab400f12418e9f7e","5373c9346ee8449a9fcdaaf78a6ce933","6ec35744af0b46f0900966ccef12a3df","3c1578ca1c6f43f0acda8d16cca2fc0f","28c37a0d7c3641c09da0bc620ff6cf73","8df54e377c514e358e8795f533923914","2a420cd6a17e418c9c2af67af951f29d","5371f4477cef4330b4b408175e90d287","8a08931ed6084d44b616378355c8cd7d","c793e20058f24f39a3b096084ece6bef","4e344132c5b5473aab91f5c26fec60ad","26e0e7ff4c6e4570ae66fdb284271c73","88735694c91e451e9dd74ee84757890d","1f9b46616b134d9486811dc3888a09c8","98eec35068a342b890f3df8bd01f4b99","6ee1130c31c14e38b70fea4382c9be7a","fcf99eac9e104bb38f64d4379d52e2d2","51f1f9434f3c461eb2d4a6d7bcd2abb1","f9438b9ff2c7441285c44cb93ee7a236","38eff8a5b6b64d3b9a8ea4eaf1867569","8753f28f77d04f5bb515b10a670e045b","ca6f78698d8a48c5939ff43a93f2e1e7","894b668bd32a43f689d51f6631192140","ca677dbda8c6429cbbfbd96de1faaff8","3ba119d1562045d6b4f152615bfbc1da","76ea34f938074231990172eb19fed49d","8a0c6e5915534a5282d70d31a1efad17","f8a222c43c4a4cf1b0bc30a1b575e790","9a7291539d6246608e85ebd8bfdea97c","b5a07c5fa07943f991fd153409a4d4a9","0dfbe60460a640baaf671fefec7d95ab","0965ec9802f74c86a10c5aeaf5b7bae0","404a0b0b2b56401393be9fe3cfd6bc1a","e7134df3d325442ea8ae751b2b15a764","5b2111289adb40fd833948f9549aa954","e1546fef0b8f42cf8adf99e5d25c25f0","04f7955cad6340cb9af71ccdedc061a4"]},"executionInfo":{"status":"ok","timestamp":1712625580320,"user_tz":300,"elapsed":281753,"user":{"displayName":"Katherine Voss-Robinson","userId":"10124239414397994450"}},"outputId":"867d35cd-d745-4da8-c2c3-338e05968a0a"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:__main__:Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n","INFO:__main__:Training/evaluation parameters TrainingArguments(\n","_n_gpu=1,\n","accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_persistent_workers=False,\n","dataloader_pin_memory=True,\n","dataloader_prefetch_factor=None,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=False,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_steps=None,\n","evaluation_strategy=epoch,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","gradient_checkpointing_kwargs=None,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=False,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_inputs_for_metrics=False,\n","include_num_input_tokens_seen=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=/content/drive/MyDrive/266/experiments/models/4_7__5_2_contin_learn_ner_b_m/runs/Apr09_01-14-58_905e52971448,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_kwargs={},\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","neftune_noise_alpha=None,\n","no_cuda=False,\n","num_train_epochs=2,\n","optim=adamw_torch,\n","optim_args=None,\n","output_dir=/content/drive/MyDrive/266/experiments/models/4_7__5_2_contin_learn_ner_b_m,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=10,\n","per_device_train_batch_size=16,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard'],\n","resume_from_checkpoint=None,\n","run_name=2 epoch NER with continual learning - biomedical and movies,\n","save_on_each_node=False,\n","save_only_model=False,\n","save_safetensors=True,\n","save_steps=500,\n","save_strategy=epoch,\n","save_total_limit=2,\n","seed=42,\n","skip_memory_metrics=True,\n","split_batches=None,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torchdynamo=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","Using custom data configuration default-68b35fe6e3e85351\n","INFO:datasets.builder:Using custom data configuration default-68b35fe6e3e85351\n","Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","INFO:datasets.info:Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","Generating dataset json (/root/.cache/huggingface/datasets/json/default-68b35fe6e3e85351/0.0.0/ab573428e7a11a7e23eebd41a2a71665ac3789ce311cbad7049572034a9bda05)\n","INFO:datasets.builder:Generating dataset json (/root/.cache/huggingface/datasets/json/default-68b35fe6e3e85351/0.0.0/ab573428e7a11a7e23eebd41a2a71665ac3789ce311cbad7049572034a9bda05)\n","Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-68b35fe6e3e85351/0.0.0/ab573428e7a11a7e23eebd41a2a71665ac3789ce311cbad7049572034a9bda05...\n","INFO:datasets.builder:Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-68b35fe6e3e85351/0.0.0/ab573428e7a11a7e23eebd41a2a71665ac3789ce311cbad7049572034a9bda05...\n","Downloading took 0.0 min\n","INFO:datasets.download.download_manager:Downloading took 0.0 min\n","Checksum Computation took 0.0 min\n","INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n","Generating train split\n","INFO:datasets.builder:Generating train split\n"]},{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbb1c8811c4d4d9fa2e4fb292836a323"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Generating validation split\n","INFO:datasets.builder:Generating validation split\n"]},{"output_type":"display_data","data":{"text/plain":["Generating validation split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84d935590d8f435c9f1983097bb6d76f"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Generating test split\n","INFO:datasets.builder:Generating test split\n"]},{"output_type":"display_data","data":{"text/plain":["Generating test split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e56cc827f5fa4b2c918c1c87cd7ebe2b"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Unable to verify splits sizes.\n","INFO:datasets.utils.info_utils:Unable to verify splits sizes.\n","Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-68b35fe6e3e85351/0.0.0/ab573428e7a11a7e23eebd41a2a71665ac3789ce311cbad7049572034a9bda05. Subsequent calls will reuse this data.\n","INFO:datasets.builder:Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-68b35fe6e3e85351/0.0.0/ab573428e7a11a7e23eebd41a2a71665ac3789ce311cbad7049572034a9bda05. Subsequent calls will reuse this data.\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"579c7aff994c426487c4d6523c47e707"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[INFO|configuration_utils.py:728] 2024-04-09 01:15:03,155 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--roberta-base/snapshots/e2da8e2f811d1448a5b465c236feacd80ffbac7b/config.json\n","[INFO|configuration_utils.py:791] 2024-04-09 01:15:03,159 >> Model config RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"finetuning_task\": \"ner\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\",\n","    \"6\": \"LABEL_6\",\n","    \"7\": \"LABEL_7\",\n","    \"8\": \"LABEL_8\",\n","    \"9\": \"LABEL_9\",\n","    \"10\": \"LABEL_10\",\n","    \"11\": \"LABEL_11\",\n","    \"12\": \"LABEL_12\",\n","    \"13\": \"LABEL_13\",\n","    \"14\": \"LABEL_14\",\n","    \"15\": \"LABEL_15\",\n","    \"16\": \"LABEL_16\",\n","    \"17\": \"LABEL_17\",\n","    \"18\": \"LABEL_18\",\n","    \"19\": \"LABEL_19\",\n","    \"20\": \"LABEL_20\",\n","    \"21\": \"LABEL_21\",\n","    \"22\": \"LABEL_22\",\n","    \"23\": \"LABEL_23\",\n","    \"24\": \"LABEL_24\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_10\": 10,\n","    \"LABEL_11\": 11,\n","    \"LABEL_12\": 12,\n","    \"LABEL_13\": 13,\n","    \"LABEL_14\": 14,\n","    \"LABEL_15\": 15,\n","    \"LABEL_16\": 16,\n","    \"LABEL_17\": 17,\n","    \"LABEL_18\": 18,\n","    \"LABEL_19\": 19,\n","    \"LABEL_2\": 2,\n","    \"LABEL_20\": 20,\n","    \"LABEL_21\": 21,\n","    \"LABEL_22\": 22,\n","    \"LABEL_23\": 23,\n","    \"LABEL_24\": 24,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5,\n","    \"LABEL_6\": 6,\n","    \"LABEL_7\": 7,\n","    \"LABEL_8\": 8,\n","    \"LABEL_9\": 9\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.38.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a074b6d1b066458f99ae87f033193957"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[INFO|configuration_utils.py:728] 2024-04-09 01:15:03,302 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--roberta-base/snapshots/e2da8e2f811d1448a5b465c236feacd80ffbac7b/config.json\n","[INFO|configuration_utils.py:791] 2024-04-09 01:15:03,306 >> Model config RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.38.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n"]},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b61046b77284b3dbbd1c9d3411f69a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f445f33b9cf498ea18d7b303105eab8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8039d153c3a24bab91cbcbff03713ae1"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[INFO|tokenization_utils_base.py:2046] 2024-04-09 01:15:04,209 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--roberta-base/snapshots/e2da8e2f811d1448a5b465c236feacd80ffbac7b/vocab.json\n","[INFO|tokenization_utils_base.py:2046] 2024-04-09 01:15:04,210 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--roberta-base/snapshots/e2da8e2f811d1448a5b465c236feacd80ffbac7b/merges.txt\n","[INFO|tokenization_utils_base.py:2046] 2024-04-09 01:15:04,211 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--roberta-base/snapshots/e2da8e2f811d1448a5b465c236feacd80ffbac7b/tokenizer.json\n","[INFO|tokenization_utils_base.py:2046] 2024-04-09 01:15:04,215 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:2046] 2024-04-09 01:15:04,219 >> loading file special_tokens_map.json from cache at None\n","[INFO|tokenization_utils_base.py:2046] 2024-04-09 01:15:04,222 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--roberta-base/snapshots/e2da8e2f811d1448a5b465c236feacd80ffbac7b/tokenizer_config.json\n","[INFO|configuration_utils.py:728] 2024-04-09 01:15:04,226 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--roberta-base/snapshots/e2da8e2f811d1448a5b465c236feacd80ffbac7b/config.json\n","[INFO|configuration_utils.py:791] 2024-04-09 01:15:04,232 >> Model config RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.38.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n"]},{"output_type":"display_data","data":{"text/plain":["Running tokenizer on train dataset:   0%|          | 0/7820 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28c37a0d7c3641c09da0bc620ff6cf73"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Caching processed dataset at /root/.cache/huggingface/datasets/json/default-68b35fe6e3e85351/0.0.0/ab573428e7a11a7e23eebd41a2a71665ac3789ce311cbad7049572034a9bda05/cache-ed1248a04b60daab.arrow\n","INFO:datasets.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/json/default-68b35fe6e3e85351/0.0.0/ab573428e7a11a7e23eebd41a2a71665ac3789ce311cbad7049572034a9bda05/cache-ed1248a04b60daab.arrow\n"]},{"output_type":"display_data","data":{"text/plain":["Running tokenizer on validation dataset:   0%|          | 0/1955 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ee1130c31c14e38b70fea4382c9be7a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Caching processed dataset at /root/.cache/huggingface/datasets/json/default-68b35fe6e3e85351/0.0.0/ab573428e7a11a7e23eebd41a2a71665ac3789ce311cbad7049572034a9bda05/cache-783c160c7b1f96ba.arrow\n","INFO:datasets.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/json/default-68b35fe6e3e85351/0.0.0/ab573428e7a11a7e23eebd41a2a71665ac3789ce311cbad7049572034a9bda05/cache-783c160c7b1f96ba.arrow\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/6.34k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a0c6e5915534a5282d70d31a1efad17"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n","[INFO|trainer.py:759] 2024-04-09 01:15:20,714 >> The following columns in the training set don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `RobertaForTokenClassification.forward`,  you can safely ignore this message.\n","[INFO|trainer.py:1812] 2024-04-09 01:15:20,757 >> ***** Running training *****\n","[INFO|trainer.py:1813] 2024-04-09 01:15:20,763 >>   Num examples = 7,820\n","[INFO|trainer.py:1814] 2024-04-09 01:15:20,765 >>   Num Epochs = 2\n","[INFO|trainer.py:1815] 2024-04-09 01:15:20,770 >>   Instantaneous batch size per device = 16\n","[INFO|trainer.py:1818] 2024-04-09 01:15:20,773 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n","[INFO|trainer.py:1819] 2024-04-09 01:15:20,777 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:1820] 2024-04-09 01:15:20,779 >>   Total optimization steps = 978\n","[INFO|trainer.py:1821] 2024-04-09 01:15:20,791 >>   Number of trainable parameters = 124,074,265\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='978' max='978' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [978/978 03:16, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.235213</td>\n","      <td>0.855960</td>\n","      <td>0.866527</td>\n","      <td>0.861211</td>\n","      <td>0.939808</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.388600</td>\n","      <td>0.206206</td>\n","      <td>0.874599</td>\n","      <td>0.888656</td>\n","      <td>0.881571</td>\n","      <td>0.946297</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[INFO|trainer.py:759] 2024-04-09 01:15:59,808 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `RobertaForTokenClassification.forward`,  you can safely ignore this message.\n","[INFO|trainer.py:3376] 2024-04-09 01:15:59,813 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3378] 2024-04-09 01:15:59,815 >>   Num examples = 1955\n","[INFO|trainer.py:3381] 2024-04-09 01:15:59,818 >>   Batch size = 10\n","/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","[INFO|trainer.py:3067] 2024-04-09 01:16:52,025 >> Saving model checkpoint to /content/drive/MyDrive/266/experiments/models/4_7__5_2_contin_learn_ner_b_m/tmp-checkpoint-489\n","[INFO|configuration_utils.py:473] 2024-04-09 01:16:52,034 >> Configuration saved in /content/drive/MyDrive/266/experiments/models/4_7__5_2_contin_learn_ner_b_m/tmp-checkpoint-489/config.json\n","[INFO|modeling_utils.py:2454] 2024-04-09 01:16:54,066 >> Model weights saved in /content/drive/MyDrive/266/experiments/models/4_7__5_2_contin_learn_ner_b_m/tmp-checkpoint-489/model.safetensors\n","[INFO|tokenization_utils_base.py:2459] 2024-04-09 01:16:54,079 >> tokenizer config file saved in /content/drive/MyDrive/266/experiments/models/4_7__5_2_contin_learn_ner_b_m/tmp-checkpoint-489/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2468] 2024-04-09 01:16:54,896 >> Special tokens file saved in /content/drive/MyDrive/266/experiments/models/4_7__5_2_contin_learn_ner_b_m/tmp-checkpoint-489/special_tokens_map.json\n","[INFO|trainer.py:759] 2024-04-09 01:17:31,891 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `RobertaForTokenClassification.forward`,  you can safely ignore this message.\n","[INFO|trainer.py:3376] 2024-04-09 01:17:31,898 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3378] 2024-04-09 01:17:31,899 >>   Num examples = 1955\n","[INFO|trainer.py:3381] 2024-04-09 01:17:31,902 >>   Batch size = 10\n","[INFO|trainer.py:3067] 2024-04-09 01:18:24,599 >> Saving model checkpoint to /content/drive/MyDrive/266/experiments/models/4_7__5_2_contin_learn_ner_b_m/tmp-checkpoint-978\n","[INFO|configuration_utils.py:473] 2024-04-09 01:18:24,609 >> Configuration saved in /content/drive/MyDrive/266/experiments/models/4_7__5_2_contin_learn_ner_b_m/tmp-checkpoint-978/config.json\n","[INFO|modeling_utils.py:2454] 2024-04-09 01:18:27,912 >> Model weights saved in /content/drive/MyDrive/266/experiments/models/4_7__5_2_contin_learn_ner_b_m/tmp-checkpoint-978/model.safetensors\n","[INFO|tokenization_utils_base.py:2459] 2024-04-09 01:18:27,930 >> tokenizer config file saved in /content/drive/MyDrive/266/experiments/models/4_7__5_2_contin_learn_ner_b_m/tmp-checkpoint-978/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2468] 2024-04-09 01:18:27,940 >> Special tokens file saved in /content/drive/MyDrive/266/experiments/models/4_7__5_2_contin_learn_ner_b_m/tmp-checkpoint-978/special_tokens_map.json\n","[INFO|trainer.py:2067] 2024-04-09 01:18:38,960 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","[INFO|trainer.py:3067] 2024-04-09 01:18:38,982 >> Saving model checkpoint to /content/drive/MyDrive/266/experiments/models/4_7__5_2_contin_learn_ner_b_m\n","[INFO|configuration_utils.py:473] 2024-04-09 01:18:39,000 >> Configuration saved in /content/drive/MyDrive/266/experiments/models/4_7__5_2_contin_learn_ner_b_m/config.json\n","[INFO|modeling_utils.py:2454] 2024-04-09 01:18:42,404 >> Model weights saved in /content/drive/MyDrive/266/experiments/models/4_7__5_2_contin_learn_ner_b_m/model.safetensors\n","[INFO|tokenization_utils_base.py:2459] 2024-04-09 01:18:42,433 >> tokenizer config file saved in /content/drive/MyDrive/266/experiments/models/4_7__5_2_contin_learn_ner_b_m/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2468] 2024-04-09 01:18:42,448 >> Special tokens file saved in /content/drive/MyDrive/266/experiments/models/4_7__5_2_contin_learn_ner_b_m/special_tokens_map.json\n","INFO:__main__:*** Evaluate ***\n","[INFO|trainer.py:759] 2024-04-09 01:18:42,764 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: ner_tags, tokens. If ner_tags, tokens are not expected by `RobertaForTokenClassification.forward`,  you can safely ignore this message.\n","[INFO|trainer.py:3376] 2024-04-09 01:18:42,768 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3378] 2024-04-09 01:18:42,772 >>   Num examples = 1955\n","[INFO|trainer.py:3381] 2024-04-09 01:18:42,775 >>   Batch size = 10\n"]},{"output_type":"stream","name":"stdout","text":["***** train metrics *****\n","  epoch                    =        2.0\n","  total_flos               =   177694GF\n","  train_loss               =     0.2938\n","  train_runtime            = 0:03:18.16\n","  train_samples            =       7820\n","  train_samples_per_second =     78.922\n","  train_steps_per_second   =      4.935\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='196' max='196' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [196/196 00:56]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["***** eval metrics *****\n","  epoch                   =        2.0\n","  eval_accuracy           =     0.9463\n","  eval_f1                 =     0.8816\n","  eval_loss               =     0.2062\n","  eval_precision          =     0.8746\n","  eval_recall             =     0.8887\n","  eval_runtime            = 0:00:57.12\n","  eval_samples            =       1955\n","  eval_samples_per_second =     34.224\n","  eval_steps_per_second   =      3.431\n"]},{"output_type":"stream","name":"stderr","text":["[INFO|modelcard.py:450] 2024-04-09 01:19:40,183 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Token Classification', 'type': 'token-classification'}, 'metrics': [{'name': 'Precision', 'type': 'precision', 'value': 0.8745988078862907}, {'name': 'Recall', 'type': 'recall', 'value': 0.8886559515490333}, {'name': 'F1', 'type': 'f1', 'value': 0.8815713460427499}, {'name': 'Accuracy', 'type': 'accuracy', 'value': 0.9462966660011979}]}\n"]}],"source":["if model_args.use_auth_token is not None:\n","    warnings.warn(\n","        \"The `use_auth_token` argument is deprecated and will be removed in v4.34. Please use `token` instead.\",\n","        FutureWarning,\n","    )\n","    if model_args.token is not None:\n","        raise ValueError(\"`token` and `use_auth_token` are both specified. Please set only the argument `token`.\")\n","    model_args.token = model_args.use_auth_token\n","\n","# Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n","# information sent is the one passed as arguments along with your Python/PyTorch versions.\n","send_example_telemetry(\"run_ner\", model_args, data_args)\n","\n","# Setup logging\n","logging.basicConfig(\n","    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n","    datefmt=\"%m/%d/%Y %H:%M:%S\",\n","    handlers=[logging.StreamHandler(sys.stdout)],\n",")\n","\n","if training_args.should_log:\n","    # The default of training_args.log_level is passive, so we set log level at info here to have that default.\n","    transformers.utils.logging.set_verbosity_info()\n","\n","log_level = training_args.get_process_log_level()\n","logger.setLevel(log_level)\n","datasets.utils.logging.set_verbosity(log_level)\n","transformers.utils.logging.set_verbosity(log_level)\n","transformers.utils.logging.enable_default_handler()\n","transformers.utils.logging.enable_explicit_format()\n","\n","# Log on each process the small summary:\n","logger.warning(\n","    f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}, \"\n","    + f\"distributed training: {training_args.parallel_mode.value == 'distributed'}, 16-bits training: {training_args.fp16}\"\n",")\n","logger.info(f\"Training/evaluation parameters {training_args}\")\n","\n","# Detecting last checkpoint.\n","last_checkpoint = None\n","if os.path.isdir(training_args.output_dir) and training_args.do_train and not training_args.overwrite_output_dir:\n","    last_checkpoint = get_last_checkpoint(training_args.output_dir)\n","    if last_checkpoint is None and len(os.listdir(training_args.output_dir)) > 0:\n","        raise ValueError(\n","            f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\n","            \"Use --overwrite_output_dir to overcome.\"\n","        )\n","    elif last_checkpoint is not None and training_args.resume_from_checkpoint is None:\n","        logger.info(\n","            f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"\n","            \"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"\n","        )\n","\n","# Set seed before initializing model.\n","set_seed(training_args.seed)\n","\n","# Get the datasets: you can either provide your own CSV/JSON/TXT training and evaluation files (see below)\n","# or just provide the name of one of the public datasets available on the hub at https://huggingface.co/datasets/\n","# (the dataset will be downloaded automatically from the datasets Hub).\n","#\n","# For CSV/JSON files, this script will use the column called 'text' or the first column if no column called\n","# 'text' is found. You can easily tweak this behavior (see below).\n","#\n","# In distributed training, the load_dataset function guarantee that only one local process can concurrently\n","# download the dataset.\n","if data_args.dataset_name is not None:\n","    # Downloading and loading a dataset from the hub.\n","    raw_datasets = load_dataset(\n","        data_args.dataset_name,\n","        data_args.dataset_config_name,\n","        cache_dir=model_args.cache_dir,\n","        token=model_args.token,\n","    )\n","else:\n","    data_files = {}\n","    if data_args.train_file is not None:\n","        data_files[\"train\"] = data_args.train_file\n","        extension = data_args.train_file.split(\".\")[-1]\n","\n","    if data_args.validation_file is not None:\n","        data_files[\"validation\"] = data_args.validation_file\n","        extension = data_args.validation_file.split(\".\")[-1]\n","    if data_args.test_file is not None:\n","        data_files[\"test\"] = data_args.test_file\n","        extension = data_args.test_file.split(\".\")[-1]\n","    raw_datasets = load_dataset(\n","        extension,\n","        data_files=data_files,\n","        cache_dir=model_args.cache_dir\n","        )\n","# See more about loading any type of standard or custom dataset (from files, python dict, pandas DataFrame, etc) at\n","# https://huggingface.co/docs/datasets/loading_datasets.\n","\n","if training_args.do_train:\n","    column_names = raw_datasets[\"train\"].column_names\n","    features = raw_datasets[\"train\"].features\n","else:\n","    column_names = raw_datasets[\"validation\"].column_names\n","    features = raw_datasets[\"validation\"].features\n","\n","if data_args.text_column_name is not None:\n","    text_column_name = data_args.text_column_name\n","elif \"tokens\" in column_names:\n","    text_column_name = \"tokens\"\n","else:\n","    text_column_name = column_names[0]\n","\n","if data_args.label_column_name is not None:\n","    label_column_name = data_args.label_column_name\n","elif f\"{data_args.task_name}_tags\" in column_names:\n","    label_column_name = f\"{data_args.task_name}_tags\"\n","else:\n","    label_column_name = column_names[1]\n","\n","# In the event the labels are not a `Sequence[ClassLabel]`, we will need to go through the dataset to get the\n","# unique labels.\n","def get_label_list(labels):\n","    unique_labels = set()\n","    for label in labels:\n","        unique_labels = unique_labels | set(label)\n","    label_list = list(unique_labels)\n","    label_list.sort()\n","    return label_list\n","\n","# If the labels are of type ClassLabel, they are already integers and we have the map stored somewhere.\n","# Otherwise, we have to get the list of labels manually.\n","\n","if data_args.dataset_name is not None: # Runs the following if using a Hugging Face DF\n","  labels_are_int = isinstance(features[label_column_name].feature, ClassLabel)\n","  if labels_are_int:\n","      label_list = features[label_column_name].feature.names\n","      label_to_id = {i: i for i in range(len(label_list))}\n","  else:\n","      label_list = get_label_list(raw_datasets[\"train\"][label_column_name])\n","      label_to_id = {l: i for i, l in enumerate(label_list)}\n","else: # Runs the following if using our own data\n","  # This is far from ideal but I'm tired of fighting it so I'm hard coding this in\n","  label_list = train_tag_scheme\n","  label_to_id = {l: i for i, l in enumerate(label_list)}\n","\n","num_labels = len(label_list)\n","\n","# Load pretrained model and tokenizer\n","#\n","# Distributed training:\n","# The .from_pretrained methods guarantee that only one local process can concurrently\n","# download model & vocab.\n","config = AutoConfig.from_pretrained(\n","    model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n","    num_labels=num_labels,\n","    finetuning_task=data_args.task_name,\n","    cache_dir=model_args.cache_dir,\n","    revision=model_args.model_revision,\n","    token=model_args.token,\n","    trust_remote_code=model_args.trust_remote_code,\n",")\n","\n","tokenizer_name_or_path = model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path\n","if config.model_type in {\"bloom\", \"gpt2\", \"roberta\"}:\n","    tokenizer = AutoTokenizer.from_pretrained(\n","        tokenizer_name_or_path,\n","        cache_dir=model_args.cache_dir,\n","        use_fast=True,\n","        revision=model_args.model_revision,\n","        token=model_args.token,\n","        trust_remote_code=model_args.trust_remote_code,\n","        add_prefix_space=True,\n","    )\n","else:\n","    tokenizer = AutoTokenizer.from_pretrained(\n","        tokenizer_name_or_path,\n","        cache_dir=model_args.cache_dir,\n","        use_fast=True,\n","        revision=model_args.model_revision,\n","        token=model_args.token,\n","        trust_remote_code=model_args.trust_remote_code,\n","    )\n","\n","model = RobertaForTokenClassification(config=config)\n","\n","\n","# Tokenizer check: this script requires a fast tokenizer.\n","if not isinstance(tokenizer, PreTrainedTokenizerFast):\n","    raise ValueError(\n","        \"This example script only works for models that have a fast tokenizer. Checkout the big table of models at\"\n","        \" https://huggingface.co/transformers/index.html#supported-frameworks to find the model types that meet\"\n","        \" this requirement\"\n","    )\n","\n","# Model has labels -> use them.\n","if model.config.label2id != PretrainedConfig(num_labels=num_labels).label2id:\n","    if sorted(model.config.label2id.keys()) == sorted(label_list):\n","        # Reorganize `label_list` to match the ordering of the model.\n","        if labels_are_int:\n","            label_to_id = {i: int(model.config.label2id[l]) for i, l in enumerate(label_list)}\n","            label_list = [model.config.id2label[i] for i in range(num_labels)]\n","        else:\n","            label_list = [model.config.id2label[i] for i in range(num_labels)]\n","            label_to_id = {l: i for i, l in enumerate(label_list)}\n","    else:\n","        logger.warning(\n","            \"Your model seems to have been trained with labels, but they don't match the dataset: \",\n","            f\"model labels: {sorted(model.config.label2id.keys())}, dataset labels:\"\n","            f\" {sorted(label_list)}.\\nIgnoring the model labels as a result.\",\n","        )\n","\n","# Set the correspondences label/ID inside the model config\n","model.config.label2id = {l: i for i, l in enumerate(label_list)}\n","model.config.id2label = dict(enumerate(label_list))\n","\n","# Map that sends B-Xxx label to its I-Xxx counterpart\n","b_to_i_label = []\n","for idx, label in enumerate(label_list):\n","    if label.startswith(\"B-\") and label.replace(\"B-\", \"I-\") in label_list:\n","        b_to_i_label.append(label_list.index(label.replace(\"B-\", \"I-\")))\n","    else:\n","        b_to_i_label.append(idx)\n","\n","# Preprocessing the dataset\n","# Padding strategy\n","padding = \"max_length\" if data_args.pad_to_max_length else False\n","\n","# Tokenize all texts and align the labels with them.\n","def tokenize_and_align_labels(examples):\n","    tokenized_inputs = tokenizer(\n","        examples[text_column_name],\n","        padding=padding,\n","        truncation=True,\n","        max_length=data_args.max_seq_length,\n","        # We use this argument because the texts in our dataset are lists of words (with a label for each word).\n","        is_split_into_words=True,\n","    )\n","    labels = []\n","    for i, label in enumerate(examples[label_column_name]):\n","        word_ids = tokenized_inputs.word_ids(batch_index=i)\n","        previous_word_idx = None\n","        label_ids = []\n","        for word_idx in word_ids:\n","            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n","            # ignored in the loss function.\n","            if word_idx is None:\n","                label_ids.append(-100)\n","            # We set the label for the first token of each word.\n","            elif word_idx != previous_word_idx:\n","                label_ids.append(label_to_id[label[word_idx]])\n","            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n","            # the label_all_tokens flag.\n","            else:\n","                if data_args.label_all_tokens:\n","                    label_ids.append(b_to_i_label[label_to_id[label[word_idx]]])\n","                else:\n","                    label_ids.append(-100)\n","            previous_word_idx = word_idx\n","\n","        labels.append(label_ids)\n","    tokenized_inputs[\"labels\"] = labels\n","    return tokenized_inputs\n","\n","if training_args.do_train:\n","    if \"train\" not in raw_datasets:\n","        raise ValueError(\"--do_train requires a train dataset\")\n","    train_dataset = raw_datasets[\"train\"]\n","    if data_args.max_train_samples is not None:\n","        max_train_samples = min(len(train_dataset), data_args.max_train_samples)\n","        train_dataset = train_dataset.select(range(max_train_samples))\n","    with training_args.main_process_first(desc=\"train dataset map pre-processing\"):\n","        train_dataset = train_dataset.map(\n","            tokenize_and_align_labels,\n","            batched=True,\n","            num_proc=data_args.preprocessing_num_workers,\n","            load_from_cache_file=not data_args.overwrite_cache,\n","            desc=\"Running tokenizer on train dataset\",\n","        )\n","\n","if training_args.do_eval:\n","    if \"validation\" not in raw_datasets:\n","        raise ValueError(\"--do_eval requires a validation dataset\")\n","    eval_dataset = raw_datasets[\"validation\"]\n","    if data_args.max_eval_samples is not None:\n","        max_eval_samples = min(len(eval_dataset), data_args.max_eval_samples)\n","        eval_dataset = eval_dataset.select(range(max_eval_samples))\n","    with training_args.main_process_first(desc=\"validation dataset map pre-processing\"):\n","        eval_dataset = eval_dataset.map(\n","            tokenize_and_align_labels,\n","            batched=True,\n","            num_proc=data_args.preprocessing_num_workers,\n","            load_from_cache_file=not data_args.overwrite_cache,\n","            desc=\"Running tokenizer on validation dataset\",\n","        )\n","\n","if training_args.do_predict:\n","    if \"test\" not in raw_datasets:\n","        raise ValueError(\"--do_predict requires a test dataset\")\n","    predict_dataset = raw_datasets[\"test\"]\n","    if data_args.max_predict_samples is not None:\n","        max_predict_samples = min(len(predict_dataset), data_args.max_predict_samples)\n","        predict_dataset = predict_dataset.select(range(max_predict_samples))\n","    with training_args.main_process_first(desc=\"prediction dataset map pre-processing\"):\n","        predict_dataset = predict_dataset.map(\n","            tokenize_and_align_labels,\n","            batched=True,\n","            num_proc=data_args.preprocessing_num_workers,\n","            load_from_cache_file=not data_args.overwrite_cache,\n","            desc=\"Running tokenizer on prediction dataset\",\n","        )\n","\n","# Data collator\n","data_collator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of=8 if training_args.fp16 else None)\n","\n","# Metrics\n","metric = evaluate.load(\"seqeval\", cache_dir=model_args.cache_dir)\n","\n","def compute_metrics(p):\n","    predictions, labels = p\n","    predictions = np.argmax(predictions, axis=2)\n","\n","    # Remove ignored index (special tokens)\n","    true_predictions = [\n","        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","    true_labels = [\n","        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","\n","    results = metric.compute(predictions=true_predictions, references=true_labels)\n","    if data_args.return_entity_level_metrics:\n","        # Unpack nested dictionaries\n","        final_results = {}\n","        for key, value in results.items():\n","            if isinstance(value, dict):\n","                for n, v in value.items():\n","                    final_results[f\"{key}_{n}\"] = v\n","            else:\n","                final_results[key] = value\n","        return final_results\n","    else:\n","        return {\n","            \"precision\": results[\"overall_precision\"],\n","            \"recall\": results[\"overall_recall\"],\n","            \"f1\": results[\"overall_f1\"],\n","            \"accuracy\": results[\"overall_accuracy\"],\n","        }\n","\n","# Initialize our Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset if training_args.do_train else None,\n","    eval_dataset=eval_dataset if training_args.do_eval else None,\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n","    callbacks=[metrics_logger],\n",")\n","\n","# Training\n","if training_args.do_train:\n","    checkpoint = None\n","    if training_args.resume_from_checkpoint is not None:\n","        checkpoint = training_args.resume_from_checkpoint\n","    elif last_checkpoint is not None:\n","        checkpoint = last_checkpoint\n","    train_result = trainer.train(resume_from_checkpoint=checkpoint)\n","    metrics = train_result.metrics\n","    trainer.save_model()  # Saves the tokenizer too for easy upload\n","\n","    max_train_samples = (\n","        data_args.max_train_samples if data_args.max_train_samples is not None else len(train_dataset)\n","    )\n","    metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n","\n","    trainer.log_metrics(\"train\", metrics)\n","    trainer.save_metrics(\"train\", metrics)\n","    trainer.save_state()\n","\n","# Evaluation\n","if training_args.do_eval:\n","    logger.info(\"*** Evaluate ***\")\n","\n","    metrics = trainer.evaluate()\n","\n","    max_eval_samples = data_args.max_eval_samples if data_args.max_eval_samples is not None else len(eval_dataset)\n","    metrics[\"eval_samples\"] = min(max_eval_samples, len(eval_dataset))\n","\n","    trainer.log_metrics(\"eval\", metrics)\n","    trainer.save_metrics(\"eval\", metrics)\n","\n","# Predict\n","if training_args.do_predict:\n","    logger.info(\"*** Predict ***\")\n","\n","    predictions, labels, metrics = trainer.predict(predict_dataset, metric_key_prefix=\"predict\")\n","    predictions = np.argmax(predictions, axis=2)\n","\n","    # Remove ignored index (special tokens)\n","    true_predictions = [\n","        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","\n","    trainer.log_metrics(\"predict\", metrics)\n","    trainer.save_metrics(\"predict\", metrics)\n","\n","    # Save predictions\n","    output_predictions_file = os.path.join(training_args.output_dir, \"predictions.txt\")\n","    if trainer.is_world_process_zero():\n","        with open(output_predictions_file, \"w\") as writer:\n","            for prediction in true_predictions:\n","                writer.write(\" \".join(prediction) + \"\\n\")\n","\n","kwargs = {\"finetuned_from\": model_args.model_name_or_path, \"tasks\": \"token-classification\"}\n","if data_args.dataset_name is not None:\n","    kwargs[\"dataset_tags\"] = data_args.dataset_name\n","    if data_args.dataset_config_name is not None:\n","        kwargs[\"dataset_args\"] = data_args.dataset_config_name\n","        kwargs[\"dataset\"] = f\"{data_args.dataset_name} {data_args.dataset_config_name}\"\n","    else:\n","        kwargs[\"dataset\"] = data_args.dataset_name\n","\n","if training_args.push_to_hub:\n","    trainer.push_to_hub(**kwargs)\n","else:\n","    trainer.create_model_card(**kwargs)\n","TRAINED_MODEL = model\n"]},{"cell_type":"markdown","metadata":{"id":"2whkQbPeZ6zI"},"source":["## Save Model Weights\n","For use in TDAPT\n","\n"]},{"cell_type":"code","source":["# Fetching Roberta specific weights\n","roberta_weights = {k: v for k, v in TRAINED_MODEL.state_dict().items() if k.startswith('roberta')}"],"metadata":{"id":"fIlI7sHxV-xn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.save(roberta_weights, output_path + '/ner_weights.pt') # These will always drop in the model output folder and use the same name"],"metadata":{"id":"WiboVmlxZAaE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"J9F1RuIPFyND"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"16nq_G0fn-Z5dXDvDuKNmtbgRtYFxujKP","timestamp":1712236929314},{"file_id":"1PQxl9bHrT02ZkfLlWdbbOxrlFZ-zDEop","timestamp":1710664142952}],"gpuType":"V100","toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"dbb1c8811c4d4d9fa2e4fb292836a323":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fb3701fa799e4eb4b43c6bfd22c0a15f","IPY_MODEL_2ce42f59ec0e4b6b992276ae56d369e3","IPY_MODEL_bbb5346c4afb4df2a98783fdb1805985"],"layout":"IPY_MODEL_788fa5f4ce2d4c88ad1b5d6dbc0336c8"}},"fb3701fa799e4eb4b43c6bfd22c0a15f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8302db96cbd4a1685b33e540d17b6e1","placeholder":"​","style":"IPY_MODEL_5dae9c6b7f3e4a10be0a3dbf56963749","value":"Generating train split: "}},"2ce42f59ec0e4b6b992276ae56d369e3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7ee75ead4a9408b9a010c4b6b94a8a6","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_30be6b1eb4324429ac6524350c72af53","value":1}},"bbb5346c4afb4df2a98783fdb1805985":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_78140dbb088f48bd9d86e1e9781f21bf","placeholder":"​","style":"IPY_MODEL_40f75f206ff44b1fb1615d904b8457ea","value":" 7820/0 [00:00&lt;00:00, 21791.37 examples/s]"}},"788fa5f4ce2d4c88ad1b5d6dbc0336c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8302db96cbd4a1685b33e540d17b6e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5dae9c6b7f3e4a10be0a3dbf56963749":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c7ee75ead4a9408b9a010c4b6b94a8a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"30be6b1eb4324429ac6524350c72af53":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"78140dbb088f48bd9d86e1e9781f21bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40f75f206ff44b1fb1615d904b8457ea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"84d935590d8f435c9f1983097bb6d76f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5891b70f75fb489e9ac1a68f61031891","IPY_MODEL_5c8fc6acb7e34bf58fa45c1e2c48c437","IPY_MODEL_b3b24312fc0640bc8a94fe376d51fb21"],"layout":"IPY_MODEL_7f399cb4ef234738a78a5bb5952ab680"}},"5891b70f75fb489e9ac1a68f61031891":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dcdb3706d5df4ea18395c4d401e3bbf2","placeholder":"​","style":"IPY_MODEL_129f0b5d67f8468399749cfd31708fb2","value":"Generating validation split: "}},"5c8fc6acb7e34bf58fa45c1e2c48c437":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb6b0bb24bff4eff91bf097c950db89d","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bdbecbd96e8845d6bc079041794af0b5","value":1}},"b3b24312fc0640bc8a94fe376d51fb21":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_527672a9e35c47958a03adca021056b7","placeholder":"​","style":"IPY_MODEL_220c2462b2d54b1383e54f96c19d90eb","value":" 1955/0 [00:00&lt;00:00, 19753.90 examples/s]"}},"7f399cb4ef234738a78a5bb5952ab680":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dcdb3706d5df4ea18395c4d401e3bbf2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"129f0b5d67f8468399749cfd31708fb2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb6b0bb24bff4eff91bf097c950db89d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"bdbecbd96e8845d6bc079041794af0b5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"527672a9e35c47958a03adca021056b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"220c2462b2d54b1383e54f96c19d90eb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e56cc827f5fa4b2c918c1c87cd7ebe2b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e301e0a04534462ebdd130f254c02886","IPY_MODEL_38417de0008243c48f0243614462ffa9","IPY_MODEL_2159399cfabc4c9988f8cc4dc0098748"],"layout":"IPY_MODEL_773741643c3045c981ce86aec8a330bf"}},"e301e0a04534462ebdd130f254c02886":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_73b89b71afab42a5b2496cf2628f8838","placeholder":"​","style":"IPY_MODEL_2edd187ecfc0480faecfd03e1c34f5bd","value":"Generating test split: "}},"38417de0008243c48f0243614462ffa9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c60c303480ee4e2ea29355a9968e103f","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aee32518e33a4cb4b197fe8a27017a03","value":1}},"2159399cfabc4c9988f8cc4dc0098748":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7ff3fa532914a0385ecf1ab45462f2b","placeholder":"​","style":"IPY_MODEL_82070506e9bd48128b0325d4c7301a61","value":" 2443/0 [00:00&lt;00:00, 27206.38 examples/s]"}},"773741643c3045c981ce86aec8a330bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73b89b71afab42a5b2496cf2628f8838":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2edd187ecfc0480faecfd03e1c34f5bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c60c303480ee4e2ea29355a9968e103f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"aee32518e33a4cb4b197fe8a27017a03":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a7ff3fa532914a0385ecf1ab45462f2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82070506e9bd48128b0325d4c7301a61":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"579c7aff994c426487c4d6523c47e707":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_de0022725cc44e6cbb559182cbd13c65","IPY_MODEL_a107ffe78a7a4dd0b71d10f371dfcb07","IPY_MODEL_5e231ac7252041f79b274ccf747ac43f"],"layout":"IPY_MODEL_e233131b378d40bf8c70ed16e816c578"}},"de0022725cc44e6cbb559182cbd13c65":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff66bce20c9f419d836d90a3fdd3fc6d","placeholder":"​","style":"IPY_MODEL_67fecfc1c6184df18af53ced1d197f92","value":"config.json: 100%"}},"a107ffe78a7a4dd0b71d10f371dfcb07":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d99b98c64b147a087cb2080df03bea9","max":481,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a0349fc25ea94ac6a86cfefaa0633cbc","value":481}},"5e231ac7252041f79b274ccf747ac43f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a52384fedb5474bab862aa0af9ad484","placeholder":"​","style":"IPY_MODEL_2467796e21654844bc26dd1ad99a8bf9","value":" 481/481 [00:00&lt;00:00, 8.84kB/s]"}},"e233131b378d40bf8c70ed16e816c578":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff66bce20c9f419d836d90a3fdd3fc6d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67fecfc1c6184df18af53ced1d197f92":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d99b98c64b147a087cb2080df03bea9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0349fc25ea94ac6a86cfefaa0633cbc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2a52384fedb5474bab862aa0af9ad484":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2467796e21654844bc26dd1ad99a8bf9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a074b6d1b066458f99ae87f033193957":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9bc28df4b90e48e99e76f4881842f852","IPY_MODEL_5d822ba8887b4c49b36b60cce1b7bbee","IPY_MODEL_54aead456ce74ba6894173056339ff95"],"layout":"IPY_MODEL_946c942892784411998fc60a44facdad"}},"9bc28df4b90e48e99e76f4881842f852":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1dafdec8d3554d3bb3cb8debb585fcc3","placeholder":"​","style":"IPY_MODEL_341c9f6f03c04591b3e51c6236745c3a","value":"tokenizer_config.json: 100%"}},"5d822ba8887b4c49b36b60cce1b7bbee":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ff3e506650c4d269a80115741ff6bdc","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_25e7cc8ba310432c8c249f44c87de7a1","value":25}},"54aead456ce74ba6894173056339ff95":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2fb95822a3b64cdcbcee256158793c93","placeholder":"​","style":"IPY_MODEL_9f15c6d9a9cb4901b3782a60f5a3897c","value":" 25.0/25.0 [00:00&lt;00:00, 940B/s]"}},"946c942892784411998fc60a44facdad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1dafdec8d3554d3bb3cb8debb585fcc3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"341c9f6f03c04591b3e51c6236745c3a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5ff3e506650c4d269a80115741ff6bdc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25e7cc8ba310432c8c249f44c87de7a1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2fb95822a3b64cdcbcee256158793c93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f15c6d9a9cb4901b3782a60f5a3897c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b61046b77284b3dbbd1c9d3411f69a7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9a0444d37f74460fbad02e25bf99642e","IPY_MODEL_3e5db8b6f6c6497283c4056514bac88d","IPY_MODEL_c2fe116f3d504748892700f63ba071f8"],"layout":"IPY_MODEL_23343f15e2cb4458a49606c175466871"}},"9a0444d37f74460fbad02e25bf99642e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd4e23e85622452489f5b416f2b47f68","placeholder":"​","style":"IPY_MODEL_cecf7b274ab34664a6a8b41ac0ba7c24","value":"vocab.json: 100%"}},"3e5db8b6f6c6497283c4056514bac88d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_50b4d752b5f8452f845f92636efef08f","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f17fa467e68e4742ac95e494676173f5","value":898823}},"c2fe116f3d504748892700f63ba071f8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ff7807fe7874d88baa3e6c4f2a66d7d","placeholder":"​","style":"IPY_MODEL_ebee364c2e9a4c06a0809e07d7b5d559","value":" 899k/899k [00:00&lt;00:00, 6.80MB/s]"}},"23343f15e2cb4458a49606c175466871":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd4e23e85622452489f5b416f2b47f68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cecf7b274ab34664a6a8b41ac0ba7c24":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"50b4d752b5f8452f845f92636efef08f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f17fa467e68e4742ac95e494676173f5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3ff7807fe7874d88baa3e6c4f2a66d7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ebee364c2e9a4c06a0809e07d7b5d559":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f445f33b9cf498ea18d7b303105eab8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_955425e66d414da78b8ca8a78b4f2c1d","IPY_MODEL_526dad9b97524e8d990cbe7c3d443d0b","IPY_MODEL_79552df9b0d246129e05d4ed064f31c1"],"layout":"IPY_MODEL_f15bb8f5fba64e18878fcac51b3758b5"}},"955425e66d414da78b8ca8a78b4f2c1d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd76665db88541aeae156b2f9704d3de","placeholder":"​","style":"IPY_MODEL_eaf0772361bd430ab528b38318f2aaa2","value":"merges.txt: 100%"}},"526dad9b97524e8d990cbe7c3d443d0b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_09c9a08722f143bea42ceed3d65ee4f1","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6c9cbed4a0b847b3b88de96b112fc6d1","value":456318}},"79552df9b0d246129e05d4ed064f31c1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7e16f03c8f741e689b82cfbac39900d","placeholder":"​","style":"IPY_MODEL_488f0d7735e542a9998edd4618a8af49","value":" 456k/456k [00:00&lt;00:00, 6.03MB/s]"}},"f15bb8f5fba64e18878fcac51b3758b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd76665db88541aeae156b2f9704d3de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eaf0772361bd430ab528b38318f2aaa2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"09c9a08722f143bea42ceed3d65ee4f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c9cbed4a0b847b3b88de96b112fc6d1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e7e16f03c8f741e689b82cfbac39900d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"488f0d7735e542a9998edd4618a8af49":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8039d153c3a24bab91cbcbff03713ae1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c3606e06352142afbf858d1714cb003a","IPY_MODEL_2d0649ecddb840a6b8c02adf87af6b36","IPY_MODEL_f4a07e1c616a47c0b0bd81c27a69db7b"],"layout":"IPY_MODEL_4da93c28901447dcaa44589a2cfdac1c"}},"c3606e06352142afbf858d1714cb003a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4201e72588d43369e014a9569959d16","placeholder":"​","style":"IPY_MODEL_709b895eaa3247fca88119591b2e6893","value":"tokenizer.json: 100%"}},"2d0649ecddb840a6b8c02adf87af6b36":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_03162ce3adbc488aab400f12418e9f7e","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5373c9346ee8449a9fcdaaf78a6ce933","value":1355863}},"f4a07e1c616a47c0b0bd81c27a69db7b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ec35744af0b46f0900966ccef12a3df","placeholder":"​","style":"IPY_MODEL_3c1578ca1c6f43f0acda8d16cca2fc0f","value":" 1.36M/1.36M [00:00&lt;00:00, 12.6MB/s]"}},"4da93c28901447dcaa44589a2cfdac1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4201e72588d43369e014a9569959d16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"709b895eaa3247fca88119591b2e6893":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"03162ce3adbc488aab400f12418e9f7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5373c9346ee8449a9fcdaaf78a6ce933":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6ec35744af0b46f0900966ccef12a3df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c1578ca1c6f43f0acda8d16cca2fc0f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"28c37a0d7c3641c09da0bc620ff6cf73":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8df54e377c514e358e8795f533923914","IPY_MODEL_2a420cd6a17e418c9c2af67af951f29d","IPY_MODEL_5371f4477cef4330b4b408175e90d287"],"layout":"IPY_MODEL_8a08931ed6084d44b616378355c8cd7d"}},"8df54e377c514e358e8795f533923914":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c793e20058f24f39a3b096084ece6bef","placeholder":"​","style":"IPY_MODEL_4e344132c5b5473aab91f5c26fec60ad","value":"Running tokenizer on train dataset: 100%"}},"2a420cd6a17e418c9c2af67af951f29d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_26e0e7ff4c6e4570ae66fdb284271c73","max":7820,"min":0,"orientation":"horizontal","style":"IPY_MODEL_88735694c91e451e9dd74ee84757890d","value":7820}},"5371f4477cef4330b4b408175e90d287":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f9b46616b134d9486811dc3888a09c8","placeholder":"​","style":"IPY_MODEL_98eec35068a342b890f3df8bd01f4b99","value":" 7820/7820 [00:02&lt;00:00, 4336.81 examples/s]"}},"8a08931ed6084d44b616378355c8cd7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c793e20058f24f39a3b096084ece6bef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e344132c5b5473aab91f5c26fec60ad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"26e0e7ff4c6e4570ae66fdb284271c73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88735694c91e451e9dd74ee84757890d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1f9b46616b134d9486811dc3888a09c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98eec35068a342b890f3df8bd01f4b99":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6ee1130c31c14e38b70fea4382c9be7a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fcf99eac9e104bb38f64d4379d52e2d2","IPY_MODEL_51f1f9434f3c461eb2d4a6d7bcd2abb1","IPY_MODEL_f9438b9ff2c7441285c44cb93ee7a236"],"layout":"IPY_MODEL_38eff8a5b6b64d3b9a8ea4eaf1867569"}},"fcf99eac9e104bb38f64d4379d52e2d2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8753f28f77d04f5bb515b10a670e045b","placeholder":"​","style":"IPY_MODEL_ca6f78698d8a48c5939ff43a93f2e1e7","value":"Running tokenizer on validation dataset: 100%"}},"51f1f9434f3c461eb2d4a6d7bcd2abb1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_894b668bd32a43f689d51f6631192140","max":1955,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ca677dbda8c6429cbbfbd96de1faaff8","value":1955}},"f9438b9ff2c7441285c44cb93ee7a236":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ba119d1562045d6b4f152615bfbc1da","placeholder":"​","style":"IPY_MODEL_76ea34f938074231990172eb19fed49d","value":" 1955/1955 [00:00&lt;00:00, 4313.57 examples/s]"}},"38eff8a5b6b64d3b9a8ea4eaf1867569":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8753f28f77d04f5bb515b10a670e045b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca6f78698d8a48c5939ff43a93f2e1e7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"894b668bd32a43f689d51f6631192140":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca677dbda8c6429cbbfbd96de1faaff8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3ba119d1562045d6b4f152615bfbc1da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76ea34f938074231990172eb19fed49d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8a0c6e5915534a5282d70d31a1efad17":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f8a222c43c4a4cf1b0bc30a1b575e790","IPY_MODEL_9a7291539d6246608e85ebd8bfdea97c","IPY_MODEL_b5a07c5fa07943f991fd153409a4d4a9"],"layout":"IPY_MODEL_0dfbe60460a640baaf671fefec7d95ab"}},"f8a222c43c4a4cf1b0bc30a1b575e790":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0965ec9802f74c86a10c5aeaf5b7bae0","placeholder":"​","style":"IPY_MODEL_404a0b0b2b56401393be9fe3cfd6bc1a","value":"Downloading builder script: 100%"}},"9a7291539d6246608e85ebd8bfdea97c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7134df3d325442ea8ae751b2b15a764","max":6338,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5b2111289adb40fd833948f9549aa954","value":6338}},"b5a07c5fa07943f991fd153409a4d4a9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1546fef0b8f42cf8adf99e5d25c25f0","placeholder":"​","style":"IPY_MODEL_04f7955cad6340cb9af71ccdedc061a4","value":" 6.34k/6.34k [00:00&lt;00:00, 91.8kB/s]"}},"0dfbe60460a640baaf671fefec7d95ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0965ec9802f74c86a10c5aeaf5b7bae0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"404a0b0b2b56401393be9fe3cfd6bc1a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e7134df3d325442ea8ae751b2b15a764":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b2111289adb40fd833948f9549aa954":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e1546fef0b8f42cf8adf99e5d25c25f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04f7955cad6340cb9af71ccdedc061a4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}